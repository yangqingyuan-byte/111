# T3Time 频域分析部分详细说明

## 一、整体架构概览

```
输入时序数据 [B, N, L]
    ↓
RevIN 归一化
    ↓
    ├─→ 时域分支 (Time Domain Branch)
    │       ↓
    │   length_to_feature: [B, N, L] → [B, N, C]
    │       ↓
    │   Transformer Encoder Layers
    │       ↓
    │   时域特征 [B, N, C]
    │
    └─→ 频域分支 (Frequency Domain Branch) ⭐
            ↓
        fre_projection: [B, N, L] → [B*N, L, 1] → [B*N, L, C]
            ↓
        FreTSComponent (核心频域处理)
            ↓
        AttentionPooling: [B*N, L, C] → [B*N, C]
            ↓
        reshape: [B*N, C] → [B, N, C]
            ↓
        Transformer Encoder
            ↓
        频域特征 [B, N, C]
    ↓
Gate 融合机制
    ↓
融合特征 [B, N, C]
```

## 二、频域分支详细流程

### 2.1 输入准备阶段

**代码位置**: `forward()` 函数第159行

```python
fre_input = self.fre_projection(x_perm.reshape(B*N, L, 1))
```

**维度变化**:
- **输入**: `x_perm` = `[B, N, L]` 
  - B: batch size
  - N: num_nodes (特征维度，如7)
  - L: seq_len (序列长度，如96)
  
- **Reshape**: `[B, N, L]` → `[B*N, L, 1]`
  - 将每个节点的时序数据独立处理
  
- **投影**: `fre_projection` = `Linear(1, channel)`
  - `[B*N, L, 1]` → `[B*N, L, C]`
  - C: channel (特征维度，如64)

**示例**:
```
假设 B=32, N=7, L=96, C=64
输入: [32, 7, 96]
Reshape: [224, 96, 1]  (32*7=224)
投影: [224, 96, 64]
```

---

### 2.2 FreTSComponent 核心处理

**代码位置**: `FreTSComponent.forward()` 第59-71行

#### 步骤1: FFT变换（时域 → 频域）

```python
x_fft = torch.fft.rfft(x, dim=1, norm='ortho')
```

**维度变化**:
- **输入**: `x` = `[B*N, L, C]`
- **输出**: `x_fft` = `[B*N, L//2+1, C]` (复数)
  - `x_fft.real`: `[B*N, L//2+1, C]` (实部)
  - `x_fft.imag`: `[B*N, L//2+1, C]` (虚部)

**说明**:
- `rfft`: 实数FFT，只保留正频率部分
- `L//2+1`: 对于L=96，输出频率点数为 96//2+1 = 49
- `norm='ortho'`: 使用正交归一化，保证可逆性

**示例**:
```
输入: [224, 96, 64]
FFT后: [224, 49, 64] (复数)
  - 实部: [224, 49, 64]
  - 虚部: [224, 49, 64]
```

---

#### 步骤2: 频域MLP变换（可学习的频域操作）

```python
# 实部变换
o_real = F.relu(
    torch.einsum('blc,cd->bld', x_fft.real, self.r) - 
    torch.einsum('blc,cd->bld', x_fft.imag, self.i) + 
    self.rb
)

# 虚部变换
o_imag = F.relu(
    torch.einsum('blc,cd->bld', x_fft.imag, self.r) + 
    torch.einsum('blc,cd->bld', x_fft.real, self.i) + 
    self.ib
)
```

**参数说明**:
- `self.r`: `[C, C]` - 实部权重矩阵
- `self.i`: `[C, C]` - 虚部权重矩阵  
- `self.rb`: `[C]` - 实部偏置
- `self.ib`: `[C]` - 虚部偏置

**维度变化**:
- **输入**: 
  - `x_fft.real`: `[B*N, L//2+1, C]`
  - `x_fft.imag`: `[B*N, L//2+1, C]`
  
- **Einstein求和**:
  - `torch.einsum('blc,cd->bld', x_fft.real, self.r)`:
    - `[B*N, L//2+1, C] × [C, C]` → `[B*N, L//2+1, C]`
  
- **输出**:
  - `o_real`: `[B*N, L//2+1, C]`
  - `o_imag`: `[B*N, L//2+1, C]`

**数学原理**:
这是复数矩阵乘法的实现：
```
(real + imag*i) × (r + i*i) = (real*r - imag*i) + (imag*r + real*i)*i
```

**示例**:
```
输入实部: [224, 49, 64]
输入虚部: [224, 49, 64]
权重矩阵: [64, 64]
输出实部: [224, 49, 64]
输出虚部: [224, 49, 64]
```

---

#### 步骤3: 稀疏化机制

```python
y = torch.stack([o_real, o_imag], dim=-1)
y = F.softshrink(y, lambd=self.sparsity_threshold)
```

**维度变化**:
- **Stack**: `[B*N, L//2+1, C]` + `[B*N, L//2+1, C]` → `[B*N, L//2+1, C, 2]`
  - 最后一个维度2表示实部和虚部
  
- **SoftShrink**: 
  - 输入: `[B*N, L//2+1, C, 2]`
  - 输出: `[B*N, L//2+1, C, 2]`
  - 作用: 将小于阈值(0.009)的值置为0，实现稀疏化

**SoftShrink函数**:
```
softshrink(x) = {
    x - λ,  if x > λ
    0,      if |x| ≤ λ
    x + λ,  if x < -λ
}
```

**示例**:
```
Stack前: 
  o_real: [224, 49, 64]
  o_imag: [224, 49, 64]
Stack后: [224, 49, 64, 2]
SoftShrink后: [224, 49, 64, 2] (小值被置0)
```

---

#### 步骤4: IFFT变换（频域 → 时域）

```python
y = torch.view_as_complex(y)
out = torch.fft.irfft(y, n=L, dim=1, norm="ortho")
```

**维度变化**:
- **view_as_complex**: `[B*N, L//2+1, C, 2]` → `[B*N, L//2+1, C]` (复数)
- **IFFT**: `[B*N, L//2+1, C]` → `[B*N, L, C]`
  - `n=L`: 指定输出长度为L，恢复原始序列长度

**示例**:
```
复数表示: [224, 49, 64] (复数)
IFFT后: [224, 96, 64]
```

---

#### 步骤5: Dropout

```python
return self.dropout(out)
```

**维度变化**:
- **输入**: `[B*N, L, C]`
- **输出**: `[B*N, L, C]` (部分值被随机置0)

---

### 2.3 频域特征提取

**代码位置**: `forward()` 函数第161-162行

```python
fre_pooled = self.fre_pool(fre_processed)
fre_encoded = self.fre_encoder(fre_pooled.reshape(B, N, self.channel))
```

#### AttentionPooling

**维度变化**:
- **输入**: `fre_processed` = `[B*N, L, C]`
- **Attention权重**: `[B*N, L, 1]` (通过attention网络计算)
- **加权求和**: `[B*N, L, C] × [B*N, L, 1]` → `[B*N, C]`
- **输出**: `fre_pooled` = `[B*N, C]`

**AttentionPooling内部**:
```python
# attention网络: Linear(C) → Linear(C//2) → Linear(1)
attn_weights = softmax(attention(x))  # [B*N, L, 1]
output = (x * attn_weights).sum(dim=1)  # [B*N, C]
```

**示例**:
```
输入: [224, 96, 64]
Attention权重: [224, 96, 1]
输出: [224, 64]
```

#### Reshape + Transformer Encoder

**维度变化**:
- **Reshape**: `[B*N, C]` → `[B, N, C]`
- **Transformer Encoder**: `[B, N, C]` → `[B, N, C]`

**示例**:
```
Reshape: [224, 64] → [32, 7, 64]
Encoder: [32, 7, 64] → [32, 7, 64]
```

---

## 三、完整维度变化流程图

```
输入: [B, N, L]
    ↓
Reshape: [B*N, L, 1]
    ↓
fre_projection: [B*N, L, C]
    ↓
┌─────────────────────────────────────┐
│      FreTSComponent                 │
│                                     │
│  [B*N, L, C]                        │
│      ↓                              │
│  FFT: [B*N, L//2+1, C] (复数)       │
│      ↓                              │
│  频域MLP:                            │
│    - 实部变换: [B*N, L//2+1, C]     │
│    - 虚部变换: [B*N, L//2+1, C]     │
│      ↓                              │
│  Stack: [B*N, L//2+1, C, 2]         │
│      ↓                              │
│  SoftShrink: [B*N, L//2+1, C, 2]    │
│      ↓                              │
│  IFFT: [B*N, L, C]                  │
│      ↓                              │
│  Dropout: [B*N, L, C]               │
└─────────────────────────────────────┘
    ↓
AttentionPooling: [B*N, C]
    ↓
Reshape: [B, N, C]
    ↓
Transformer Encoder: [B, N, C]
    ↓
输出: [B, N, C]
```

---

## 四、关键设计要点

### 4.1 可学习的频域变换

**核心思想**: 在频域空间进行可学习的线性变换，而不是固定的频域滤波

**优势**:
- 自适应学习不同频率成分的重要性
- 通过复数矩阵乘法实现频域特征交互
- 比时域卷积更高效（频域操作复杂度更低）

### 4.2 稀疏化机制

**目的**: 去除噪声频率成分，保留重要频率信息

**实现**: SoftShrink函数，阈值=0.009
- 将接近0的频率系数置为0
- 减少模型复杂度，提高泛化能力

### 4.3 注意力池化

**目的**: 从频域处理后的序列中提取关键特征

**优势**:
- 自适应选择重要时间步
- 将变长序列压缩为固定长度特征向量

---

## 五、参数初始化

```python
# 在 __init__ 中
self.r = nn.Parameter(scale * torch.randn(channel, channel))  # scale=0.018
self.i = nn.Parameter(scale * torch.randn(channel, channel))
self.rb = nn.Parameter(torch.zeros(channel))
self.ib = nn.Parameter(torch.zeros(channel))
```

**初始化策略**:
- `r` 和 `i`: 使用小方差(0.018)的正态分布初始化，保证训练稳定性
- `rb` 和 `ib`: 初始化为0，从零开始学习偏置

---

## 六、与整体架构的融合

### 6.1 Gate融合机制

```python
# 时域特征: [B, N, C]
# 频域特征: [B, N, C]
# Horizon信息: [B, N, 1]

gate_input = cat([time_encoded, fre_encoded, horizon_info], dim=-1)  # [B, N, 2*C+1]
gate = fusion_gate(gate_input)  # [B, N, C]
fused_features = time_encoded + gate * fre_encoded  # [B, N, C]
```

**设计思想**:
- 使用门控机制自适应融合时域和频域特征
- 考虑预测长度(horizon)信息，不同预测长度使用不同的融合权重

---

## 七、实际运行示例

假设: B=32, N=7, L=96, C=64

```
1. 输入准备
   输入: [32, 7, 96]
   Reshape: [224, 96, 1]
   投影: [224, 96, 64]

2. FFT变换
   FFT: [224, 49, 64] (复数)

3. 频域MLP
   实部: [224, 49, 64]
   虚部: [224, 49, 64]

4. 稀疏化
   Stack: [224, 49, 64, 2]
   SoftShrink: [224, 49, 64, 2]

5. IFFT变换
   复数: [224, 49, 64]
   IFFT: [224, 96, 64]

6. 池化
   AttentionPooling: [224, 64]

7. 编码
   Reshape: [32, 7, 64]
   Encoder: [32, 7, 64]

8. 融合
   时域: [32, 7, 64]
   频域: [32, 7, 64]
   融合: [32, 7, 64]
```

---

## 八、总结

**频域分析的核心优势**:

1. **频域表示**: 通过FFT将时序数据转换到频域，捕获周期性模式
2. **可学习变换**: 使用可学习的复数矩阵在频域进行特征变换
3. **稀疏化**: 通过SoftShrink去除噪声频率，提高模型鲁棒性
4. **注意力池化**: 自适应提取关键特征，压缩序列长度
5. **门控融合**: 与时域特征自适应融合，充分利用两种表示

这种设计使得模型能够同时利用时域和频域信息，提高时间序列预测的准确性。
