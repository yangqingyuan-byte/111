# T3Time 频域分析架构图

## 一、整体架构流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                        输入数据                                  │
│                    [B, N, L]                                    │
│              (Batch, Nodes, Sequence Length)                   │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
              ┌──────────────────────┐
              │   RevIN 归一化       │
              │   Normalize Layers   │
              └──────────┬───────────┘
                         │
         ┌────────────────┴────────────────┐
         │                                  │
         ▼                                  ▼
┌──────────────────┐            ┌──────────────────────┐
│   时域分支        │            │    频域分支 ⭐        │
│ Time Domain      │            │ Frequency Domain    │
└────────┬─────────┘            └──────────┬───────────┘
         │                                  │
         ▼                                  ▼
┌──────────────────┐            ┌──────────────────────┐
│ length_to_feature│            │  fre_projection      │
│ [B,N,L]→[B,N,C]  │            │  [B,N,L]→[B*N,L,C]   │
└────────┬─────────┘            └──────────┬───────────┘
         │                                  │
         ▼                                  ▼
┌──────────────────┐            ┌──────────────────────┐
│ Transformer      │            │  FreTSComponent      │
│ Encoder Layers   │            │  (核心频域处理)       │
│ [B,N,C]→[B,N,C]  │            │  [B*N,L,C]→[B*N,L,C] │
└────────┬─────────┘            └──────────┬───────────┘
         │                                  │
         │                                  ▼
         │                      ┌──────────────────────┐
         │                      │  AttentionPooling     │
         │                      │  [B*N,L,C]→[B*N,C]   │
         │                      └──────────┬───────────┘
         │                                  │
         │                                  ▼
         │                      ┌──────────────────────┐
         │                      │  Reshape             │
         │                      │  [B*N,C]→[B,N,C]     │
         │                      └──────────┬───────────┘
         │                                  │
         │                                  ▼
         │                      ┌──────────────────────┐
         │                      │  Transformer Encoder │
         │                      │  [B,N,C]→[B,N,C]     │
         │                      └──────────┬───────────┘
         │                                  │
         └──────────────────┬───────────────┘
                            │
                            ▼
              ┌─────────────────────────────┐
              │    Gate 融合机制             │
              │  (Horizon-Aware Gate)       │
              │  [B,N,C] + gate*[B,N,C]     │
              └──────────────┬───────────────┘
                            │
                            ▼
              ┌─────────────────────────────┐
              │   融合特征 [B,N,C]          │
              └──────────────┬───────────────┘
                            │
                            ▼
              ┌─────────────────────────────┐
              │   CMA & Decoder              │
              └──────────────┬───────────────┘
                            │
                            ▼
              ┌─────────────────────────────┐
              │   输出预测 [B,N,Pred_Len]   │
              └─────────────────────────────┘
```

---

## 二、FreTSComponent 详细架构图

```
输入: [B*N, L, C]
  │
  ▼
┌─────────────────────────────────────────────────────────┐
│              步骤1: FFT变换 (时域→频域)                  │
│                                                         │
│  torch.fft.rfft(x, dim=1, norm='ortho')               │
│                                                         │
│  [B*N, L, C] ────────→ [B*N, L//2+1, C] (复数)         │
│                                                         │
│  实部: [B*N, L//2+1, C]                                │
│  虚部: [B*N, L//2+1, C]                                │
└──────────────────────┬──────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────┐
│         步骤2: 频域MLP变换 (可学习频域操作)              │
│                                                         │
│  实部变换:                                             │
│    o_real = ReLU(real×r - imag×i + rb)                │
│                                                         │
│  虚部变换:                                             │
│    o_imag = ReLU(imag×r + real×i + ib)                │
│                                                         │
│  参数:                                                  │
│    r: [C, C] - 实部权重矩阵                            │
│    i: [C, C] - 虚部权重矩阵                            │
│    rb: [C] - 实部偏置                                  │
│    ib: [C] - 虚部偏置                                  │
│                                                         │
│  [B*N, L//2+1, C] ───→ [B*N, L//2+1, C]                │
└──────────────────────┬──────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────┐
│              步骤3: 稀疏化机制                          │
│                                                         │
│  Stack: [o_real, o_imag]                                │
│  [B*N, L//2+1, C] + [B*N, L//2+1, C]                   │
│         ───────→ [B*N, L//2+1, C, 2]                   │
│                                                         │
│  SoftShrink(y, λ=0.009)                                │
│  作用: 将小于阈值0.009的值置为0                        │
│                                                         │
│  [B*N, L//2+1, C, 2] ───→ [B*N, L//2+1, C, 2]         │
└──────────────────────┬──────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────┐
│              步骤4: IFFT变换 (频域→时域)                 │
│                                                         │
│  view_as_complex: [B*N, L//2+1, C, 2]                  │
│         ───────→ [B*N, L//2+1, C] (复数)               │
│                                                         │
│  torch.fft.irfft(y, n=L, dim=1, norm="ortho")         │
│                                                         │
│  [B*N, L//2+1, C] ────────→ [B*N, L, C]               │
└──────────────────────┬──────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────┐
│              步骤5: Dropout                             │
│                                                         │
│  self.dropout(out)                                     │
│                                                         │
│  [B*N, L, C] ────────→ [B*N, L, C]                     │
└─────────────────────────────────────────────────────────┘
```

---

## 三、频域MLP变换数学原理图

```
复数频域表示:
    X(f) = Real(f) + i·Imag(f)

可学习变换矩阵:
    W = R + i·I
    其中:
        R: [C, C] - 实部权重矩阵
        I: [C, C] - 虚部权重矩阵

变换操作:
    Y(f) = X(f) × W + Bias
    
展开为:
    Y_real = Real(X) × R - Imag(X) × I + rb
    Y_imag = Imag(X) × R + Real(X) × I + ib

矩阵形式:
    ┌─────────┐   ┌─────┐   ┌─────────┐   ┌─────┐
    │ Real(X) │   │  R  │   │ Imag(X) │   │  I  │
    └─────────┘   └─────┘   └─────────┘   └─────┘
         │           │           │           │
         └───────────┼───────────┘           │
                     │                       │
                     ▼                       ▼
              ┌─────────────┐         ┌─────────────┐
              │  矩阵乘法    │         │  矩阵乘法    │
              └─────────────┘         └─────────────┘
                     │                       │
                     └───────────┬───────────┘
                                 │
                                 ▼
                    ┌────────────────────┐
                    │  组合和激活        │
                    │  ReLU(·)          │
                    └──────────┬─────────┘
                               │
                               ▼
                    ┌────────────────────┐
                    │  Y_real, Y_imag    │
                    └────────────────────┘
```

---

## 四、维度变化详细追踪

### 4.1 完整流程维度变化

```
阶段1: 输入准备
─────────────────────────────────────────
输入:          [B, N, L]
Reshape:       [B*N, L, 1]
投影:          [B*N, L, C]
─────────────────────────────────────────

阶段2: FFT变换
─────────────────────────────────────────
FFT输入:       [B*N, L, C]
FFT输出:       [B*N, L//2+1, C] (复数)
  实部:        [B*N, L//2+1, C]
  虚部:        [B*N, L//2+1, C]
─────────────────────────────────────────

阶段3: 频域MLP
─────────────────────────────────────────
实部变换:
  输入:        [B*N, L//2+1, C]
  权重:        [C, C]
  输出:        [B*N, L//2+1, C]

虚部变换:
  输入:        [B*N, L//2+1, C]
  权重:        [C, C]
  输出:        [B*N, L//2+1, C]
─────────────────────────────────────────

阶段4: 稀疏化
─────────────────────────────────────────
Stack:         [B*N, L//2+1, C, 2]
SoftShrink:    [B*N, L//2+1, C, 2]
─────────────────────────────────────────

阶段5: IFFT变换
─────────────────────────────────────────
复数表示:      [B*N, L//2+1, C]
IFFT输出:      [B*N, L, C]
─────────────────────────────────────────

阶段6: 池化
─────────────────────────────────────────
输入:          [B*N, L, C]
Attention:     [B*N, L, 1]
加权求和:      [B*N, C]
─────────────────────────────────────────

阶段7: 编码
─────────────────────────────────────────
Reshape:       [B, N, C]
Encoder:       [B, N, C]
─────────────────────────────────────────
```

### 4.2 具体数值示例

假设: B=32, N=7, L=96, C=64

```
步骤              维度变化
─────────────────────────────────────────────────────
1. 输入            [32, 7, 96]
2. Reshape         [224, 96, 1]      (32×7=224)
3. 投影            [224, 96, 64]
4. FFT             [224, 49, 64]     (96//2+1=49)
5. 频域MLP          [224, 49, 64]
6. Stack           [224, 49, 64, 2]
7. SoftShrink       [224, 49, 64, 2]
8. IFFT            [224, 96, 64]
9. Dropout         [224, 96, 64]
10. AttentionPool   [224, 64]
11. Reshape        [32, 7, 64]
12. Encoder        [32, 7, 64]
```

---

## 五、关键操作详解

### 5.1 FFT变换 (rfft)

```
时域信号: x(t) = [x₀, x₁, x₂, ..., x₉₅]
                ↓ FFT
频域表示: X(f) = [X₀, X₁, X₂, ..., X₄₈]
                (49个频率点，复数)

频率点含义:
  X₀: 直流分量 (DC component)
  X₁-X₄₇: 正频率分量
  X₄₈: 奈奎斯特频率 (Nyquist frequency)
```

### 5.2 频域MLP变换

```
对于每个频率点 f:
  ┌─────────────┐     ┌─────┐     ┌─────────────┐
  │ Real(X[f])  │  ×  │  R  │  -  │ Imag(X[f])  │  ×  │  I  │  +  │ rb │
  └─────────────┘     └─────┘     └─────────────┘     └─────┘     └────┘
         │                                 │
         └─────────────┬───────────────────┘
                       │
                       ▼
                  ReLU(·)
                       │
                       ▼
                  Y_real[f]

  ┌─────────────┐     ┌─────┐     ┌─────────────┐
  │ Imag(X[f])  │  ×  │  R  │  +  │ Real(X[f])  │  ×  │  I  │  +  │ ib │
  └─────────────┘     └─────┘     └─────────────┘     └─────┘     └────┘
         │                                 │
         └─────────────┬───────────────────┘
                       │
                       ▼
                  ReLU(·)
                       │
                       ▼
                  Y_imag[f]
```

### 5.3 SoftShrink稀疏化

```
SoftShrink函数:
    y = {
        x - λ,  如果 x > λ
        0,      如果 |x| ≤ λ
        x + λ,  如果 x < -λ
    }

其中 λ = 0.009

作用:
  - 将接近0的小值置为0
  - 保留重要的频率成分
  - 减少模型复杂度
```

### 5.4 AttentionPooling

```
输入序列: [x₁, x₂, ..., x₉₆]  (每个x是C维向量)
          ↓
计算注意力权重:
    αᵢ = softmax(MLP(xᵢ))
          ↓
加权求和:
    output = Σᵢ αᵢ · xᵢ
          ↓
输出: 单个C维向量
```

---

## 六、设计优势总结

```
┌─────────────────────────────────────────────────────────┐
│  1. 频域表示优势                                        │
│     ✓ 捕获周期性模式                                    │
│     ✓ 分离不同频率成分                                  │
│     ✓ 更高效的频域操作                                  │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│  2. 可学习变换优势                                      │
│     ✓ 自适应学习重要频率                                │
│     ✓ 复数矩阵实现频域特征交互                          │
│     ✓ 比固定滤波器更灵活                                │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│  3. 稀疏化优势                                          │
│     ✓ 去除噪声频率                                      │
│     ✓ 提高模型鲁棒性                                    │
│     ✓ 减少计算复杂度                                    │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│  4. 注意力池化优势                                      │
│     ✓ 自适应选择重要时间步                              │
│     ✓ 压缩序列长度                                      │
│     ✓ 提取关键特征                                      │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│  5. 门控融合优势                                        │
│     ✓ 自适应融合时域和频域特征                          │
│     ✓ 考虑预测长度信息                                  │
│     ✓ 充分利用两种表示                                  │
└─────────────────────────────────────────────────────────┘
```

---

## 七、计算复杂度分析

```
操作              时间复杂度          空间复杂度
─────────────────────────────────────────────────────
FFT变换           O(L log L)          O(L)
频域MLP           O(L·C²)            O(C²)
SoftShrink        O(L·C)             O(1)
IFFT变换          O(L log L)          O(L)
AttentionPool     O(L·C)             O(L)

总体复杂度:
  时间复杂度: O(L log L + L·C²)
  空间复杂度: O(L + C²)

相比时域卷积的优势:
  时域卷积: O(L²·C²)
  频域操作: O(L log L + L·C²)
  
  当L较大时，频域操作更高效！
```
