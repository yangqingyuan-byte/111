# 数据维度变化详细解释

## 完整流程：从 [2, 7, 96] 到 [2, 7, 32]

### 输入说明

```
输入: [2, 7, 96]
  - 2: Batch size（2个样本）
  - 7: Number of nodes（7个节点/变量）
  - 96: Sequence length（96个时间步）
```

---

## 步骤 1: 小波包分解

### 输入 → 输出

```
输入: [2, 7, 96]
    ↓ 小波包分解 (Level=2)
输出: 4个频段，每个 [2, 7, 30]
```

### 详细说明

- **输入**: `[B=2, N=7, L=96]`
- **操作**: 小波包分解，将信号分解成4个频段
- **输出**: 4个频段，每个频段的长度约为 `L/4 ≈ 30`（考虑边界处理）

**为什么长度是30而不是24？**
- 理论上是 96/4 = 24
- 但由于小波分解的边界处理（padding），实际长度约为30

**4个频段**:
- 频段 0: `[2, 7, 30]` (cA-cA, 最低频)
- 频段 1: `[2, 7, 30]` (cA-cD, 低中频)
- 频段 2: `[2, 7, 30]` (cD-cA, 中高频)
- 频段 3: `[2, 7, 30]` (cD-cD, 最高频)

---

## 步骤 2: Reshape 和独立处理

### 关键操作：将 B 和 N 合并

这是理解的关键！**为什么要合并 B 和 N？**

**原因**: 方便并行处理所有序列（2个batch × 7个节点 = 14个序列）

### 2.1 Reshape: [2, 7, 30] → [14, 30, 1]

```python
# 代码第197行
node_reshaped = node.unsqueeze(-1).reshape(B * N, L_part, 1)
```

**详细过程**:

```
输入: [2, 7, 30]
    ↓ unsqueeze(-1)  # 在最后添加一个维度
    [2, 7, 30, 1]
    ↓ reshape(B*N, 30, 1)  # 将前两个维度合并
    [14, 30, 1]
```

**维度变化**:
- `[2, 7, 30]` → `[2, 7, 30, 1]` → `[14, 30, 1]`
- **B×N = 2×7 = 14**: 将2个batch和7个节点合并成14个序列

**含义**:
- **14个序列**: 2个batch × 7个节点 = 14个独立的时序序列
- **30个时间步**: 每个序列有30个时间步
- **1个特征**: 每个时间步只有1个特征值（小波分解后的标量）

### 2.2 独立投影: [14, 30, 1] → [14, 30, 32]

```python
# 代码第199行
tokens = proj(node_reshaped)  # Linear(1 → C)
```

**操作**: 使用 `Linear(1 → 32)` 将每个时间步的1个特征投影到32维

**维度变化**:
- 输入: `[14, 30, 1]` - 14个序列，每个30个时间步，每个1个特征
- 输出: `[14, 30, 32]` - 14个序列，每个30个时间步，每个32个特征

**含义**:
- 每个时间步从1维扩展到32维
- 为后续的编码器处理做准备

### 2.3 位置编码 + 编码器: [14, 30, 32] → [14, 30, 32]

```python
# 代码第202, 205行
tokens = tokens + self.freq_pos_embed[:, i, :].unsqueeze(1)
encoded = self.wp_encoder(tokens)
```

**操作**:
1. 添加频段位置编码（区分不同频段）
2. 通过编码器处理（Transformer）

**维度变化**: 形状不变，仍然是 `[14, 30, 32]`

**含义**: 特征被进一步编码，但维度保持不变

---

## 步骤 3: 注意力池化（关键步骤！）

### 从 [14, 30, 32] → [14, 32]

这是**最关键的维度变化**：将30个时间步压缩成1个特征向量

### 3.1 注意力权重计算

```python
# 代码第88-89行
attn_logits = self.attention(feat)  # [14, 30, 32] → [14, 30, 1]
attn_weights = F.softmax(attn_logits, dim=1)  # [14, 30, 1]
```

**操作**:
- 对每个时间步计算一个注意力分数
- Softmax归一化，使得30个时间步的权重和为1

**维度**:
- 输入: `[14, 30, 32]` - 14个序列，每个30个时间步，每个32维特征
- 输出: `[14, 30, 1]` - 14个序列，每个30个时间步，每个1个权重值

### 3.2 加权池化（对时序维度求和）

```python
# 代码第90行
pooled = (feat * attn_weights).sum(dim=1)  # [14, 30, 32] → [14, 32]
```

**详细计算**:

```
feat:        [14, 30, 32]  - 14个序列，30个时间步，32维特征
attn_weights: [14, 30, 1]   - 14个序列，30个时间步，1个权重

# 广播乘法
feat * attn_weights: [14, 30, 32]  # 每个时间步的特征乘以对应权重

# 对 dim=1 (时间维度) 求和
sum(dim=1): [14, 32]  # 30个时间步的信息压缩成1个32维向量
```

**数学公式**:
$$pooled[i] = \sum_{t=0}^{29} feat[i, t] \times attn\_weights[i, t]$$

**含义**:
- **输入**: 14个序列，每个序列有30个时间步，每个时间步32维特征
- **输出**: 14个序列，每个序列只有1个32维的特征向量
- **作用**: 将30个时间步的信息**压缩**成一个32维向量

**为什么这样做？**
- 每个频段有30个时间步，但我们需要一个固定长度的特征向量
- 注意力机制自动学习哪些时间步更重要
- 加权平均保留了重要信息，丢弃了冗余信息

---

## 步骤 4: 多频段融合

### 从 [14, 32] × 4 → [14, 32]

### 4.1 4个频段的池化结果

经过步骤3，每个频段都得到了一个 `[14, 32]` 的特征向量：

```
频段 0: [14, 32]  (最低频的池化特征)
频段 1: [14, 32]  (低中频的池化特征)
频段 2: [14, 32]  (中高频的池化特征)
频段 3: [14, 32]  (最高频的池化特征)
```

### 4.2 应用节点权重

```python
# 代码第92行
pooled_list.append(pooled * self.node_weights[i])
```

**操作**: 每个频段的特征乘以对应的可学习权重

**维度**: 仍然是 `[14, 32]`，但数值被权重缩放

### 4.3 Stack: 堆叠4个频段

```python
# 代码第95行
stacked = torch.stack(pooled_list, dim=1)  # [14, 4, 32]
```

**操作**: 将4个 `[14, 32]` 堆叠在 dim=1 上

**维度变化**:
- 输入: 4个 `[14, 32]`
- 输出: `[14, 4, 32]`

**含义**:
- 14个序列
- 每个序列有4个频段的特征
- 每个频段32维

### 4.4 Mean: 平均融合

```python
# 代码第95行
final_pooled = stacked.mean(dim=1)  # [14, 4, 32] → [14, 32]
```

**操作**: 对 dim=1 (频段维度) 求平均

**维度变化**:
- 输入: `[14, 4, 32]` - 14个序列，4个频段，每个32维
- 输出: `[14, 32]` - 14个序列，1个融合后的32维特征

**数学公式**:
$$final[i] = \frac{1}{4} \sum_{j=0}^{3} w_j \times pooled_j[i]$$

**含义**: 将4个频段的特征平均融合成一个32维向量

---

## 步骤 5: Reshape 回原始维度

### 从 [14, 32] → [2, 7, 32]

```python
# 代码第210行
return pooled.reshape(B, N, self.channel)  # [14, 32] → [2, 7, 32]
```

**操作**: 将 B*N=14 拆分成 B=2 和 N=7

**维度变化**:
- 输入: `[14, 32]` - 14个序列，每个32维
- 输出: `[2, 7, 32]` - 2个batch，每个7个节点，每个32维

**含义**: 恢复原始的 batch 和 nodes 维度结构

---

## 完整维度变化总结

```
输入: [2, 7, 96]
    ↓ 小波包分解
4个频段: [2, 7, 30] × 4
    ↓ Reshape (合并 B 和 N)
    [14, 30, 1] × 4
    ↓ 独立投影 (1 → 32)
    [14, 30, 32] × 4
    ↓ 位置编码 + 编码器
    [14, 30, 32] × 4
    ↓ 注意力池化 (对时序维度求和)
    [14, 32] × 4
    ↓ 应用节点权重
    [14, 32] × 4
    ↓ Stack (堆叠频段)
    [14, 4, 32]
    ↓ Mean (平均融合)
    [14, 32]
    ↓ Reshape (拆分 B 和 N)
输出: [2, 7, 32]
```

## 关键理解点

### 1. 为什么合并 B 和 N？

**原因**: 方便并行处理
- 将 `[B, N, L]` 变成 `[B*N, L, ...]`
- 所有序列（2×7=14个）可以并行处理
- 最后再恢复成 `[B, N, C]`

### 2. 注意力池化的作用

**作用**: 时序压缩
- 输入: `[14, 30, 32]` - 30个时间步
- 输出: `[14, 32]` - 1个特征向量
- **将多个时间步的信息压缩成一个固定长度的向量**

### 3. 多频段融合的作用

**作用**: 信息整合
- 4个频段代表不同的频率成分
- 通过平均融合，整合所有频段的信息
- 得到最终的特征表示

### 4. 为什么最终是 [2, 7, 32]？

- **2**: 2个batch（样本）
- **7**: 7个节点（变量）
- **32**: 每个节点的特征维度（channel）

**含义**: 每个节点从96个时间步压缩成一个32维的特征向量

## 可视化理解

```
原始数据:
Batch 0: Node 0: [96个时间步]
         Node 1: [96个时间步]
         ...
         Node 6: [96个时间步]
Batch 1: Node 0: [96个时间步]
         ...
         Node 6: [96个时间步]

处理后:
Batch 0: Node 0: [32维特征]
         Node 1: [32维特征]
         ...
         Node 6: [32维特征]
Batch 1: Node 0: [32维特征]
         ...
         Node 6: [32维特征]
```

**关键**: 每个节点的96个时间步被压缩成了32维的特征向量！
