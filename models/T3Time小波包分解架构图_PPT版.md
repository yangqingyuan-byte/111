# T3Time 小波包分解架构图 (PPT版本)

## 核心架构流程

```
                    ┌─────────────────────┐
                    │   输入 [B, N, L]     │
                    └──────────┬──────────┘
                               │
                               ▼
                    ┌─────────────────────┐
                    │ 小波包分解 (WPD)     │
                    │ Level=2, Wavelet=db4│
                    └──────────┬──────────┘
                               │
                ┌──────────────┴──────────────┐
                │                              │
                ▼                              ▼
        ┌───────────────┐            ┌───────────────┐
        │ Level 1: 低频 │            │ Level 1: 高频 │
        │    cA         │            │    cD         │
        └───────┬───────┘            └───────┬───────┘
                │                              │
        ┌───────┴───────┐            ┌───────┴───────┐
        │               │            │               │
        ▼               ▼            ▼               ▼
┌───────────┐  ┌───────────┐  ┌───────────┐  ┌───────────┐
│ 频段 0    │  │ 频段 1    │  │ 频段 2    │  │ 频段 3    │
│ cA-cA     │  │ cA-cD     │  │ cD-cA     │  │ cD-cD     │
│ 最低频    │  │ 中低频    │  │ 中高频    │  │ 最高频    │
│ [L/4]     │  │ [L/4]     │  │ [L/4]     │  │ [L/4]     │
└─────┬─────┘  └─────┬─────┘  └─────┬─────┘  └─────┬─────┘
      │              │              │              │
      └──────┬───────┴──────┬───────┴──────┬───────┘
             │              │              │
             ▼              ▼              ▼
      ┌──────────────────────────────────────┐
      │   独立投影层 (Linear: 1 → C)          │
      │   每个频段独立学习特征表示            │
      └──────────────┬───────────────────────┘
                     │
                     ▼
      ┌──────────────────────────────────────┐
      │   频段位置编码 (freq_pos_embed)       │
      │   区分不同频段的特征                  │
      └──────────────┬───────────────────────┘
                     │
                     ▼
      ┌──────────────────────────────────────┐
      │   GatedTransformerEncoder            │
      │   对每个频段独立编码                  │
      └──────────────┬───────────────────────┘
                     │
                     ▼
      ┌──────────────────────────────────────┐
      │   注意力池化 (Attention Pooling)      │
      │   • 频段内注意力加权                  │
      │   • 可学习节点权重                    │
      │   • 多频段融合                        │
      └──────────────┬───────────────────────┘
                     │
                     ▼
              ┌───────────┐
              │ [B, N, C] │
              └───────────┘
```

## 关键步骤说明

### 步骤 1: 小波包分解

#### 频段数量确定
- **公式**: `num_wp_nodes = 2 ** wp_level`
- **原理**: 小波包分解是递归的**二叉树结构**（不是三进制！）
  - Level 0: 1 个节点（原始信号）
  - Level 1: 每个节点分解为 2 个子节点（cA 和 cD）→ 共 2^1 = 2 个节点
  - Level 2: 每个节点再分解为 2 个子节点 → 共 2^2 = 4 个节点
  - Level 3: 每个节点再分解为 2 个子节点 → 共 2^3 = **8 个节点**（不是3个！）
  - Level n: 共 2^n 个叶子节点
  
  **重要**: Level=3 产生 **8个频段**，不是"低频、中频、高频"三个！
- **代码位置**: 
  ```python
  num_wp_nodes = 2 ** wp_level  # wp_level=2 → 4个频段
  ```
- **分解过程**:
  ```
  原始信号 [B, N, L]
      │
      ├─ Level 1: cA (低频) [B, N, L/2]
      │     ├─ Level 2: cA-cA [B, N, L/4] ← 频段 0
      │     └─ Level 2: cA-cD [B, N, L/4] ← 频段 1
      │
      └─ Level 1: cD (高频) [B, N, L/2]
            ├─ Level 2: cD-cA [B, N, L/4] ← 频段 2
            └─ Level 2: cD-cD [B, N, L/4] ← 频段 3
  ```
- **输入**: [B, N, L]
- **输出**: 4 个频段，每个 [B, N, L/4]

### 步骤 2: 独立特征投影
- 每个频段使用独立的 Linear(1→C) 层
- 学习频段特定的特征表示

### 步骤 3: 频段位置编码
- 添加可学习的频段位置编码
- 帮助模型区分不同频段

### 步骤 4: 编码与池化
- GatedTransformerEncoder 编码每个频段
- **注意力池化融合机制**（详见下方）

### 步骤 5: 多频段融合机制

#### 融合流程（WaveletPacketAttentionPooling）

```
对每个频段 i (i = 0, 1, 2, 3):
  ┌─────────────────────────────────────┐
  │ 1. 频段内注意力池化                  │
  │    attn_weights = Softmax(MLP(feat)) │
  │    pooled[i] = Σ(feat * attn_weights) │
  │    输出: [B*N, C]                    │
  └─────────────────────────────────────┘
           │
           ▼
  ┌─────────────────────────────────────┐
  │ 2. 应用可学习节点权重                │
  │    pooled[i] = pooled[i] *          │
  │              node_weights[i]        │
  │    (学习不同频段的重要性)            │
  └─────────────────────────────────────┘
           │
           ▼
  ┌─────────────────────────────────────┐
  │ 3. 收集所有频段的池化结果             │
  │    pooled_list = [pooled[0],         │
  │                   pooled[1],         │
  │                   pooled[2],         │
  │                   pooled[3]]         │
  │    形状: List of [B*N, C]            │
  └─────────────────────────────────────┘
           │
           ▼
  ┌─────────────────────────────────────┐
  │ 4. 最终融合（平均池化）               │
  │    final = Mean(pooled_list)        │
  │    输出: [B*N, C]                    │
  └─────────────────────────────────────┘
```

#### 融合机制详解

1. **频段内注意力池化**（第87-90行）:
   - 对每个频段的时序维度进行注意力加权
   - 关注每个频段内的重要时间点
   - 输出: 每个频段得到一个 [B*N, C] 的特征向量

2. **可学习节点权重**（第92行）:
   - `node_weights`: 可学习参数，形状 [num_wp_nodes]
   - 自动学习不同频段的重要性
   - 例如：如果低频更重要，node_weights[0] 会更大

3. **多频段融合**（第95行）:
   - 使用 `torch.stack` 堆叠所有频段的池化结果
   - 使用 `mean` 进行平均融合
   - 公式: `final = mean([w0*pooled[0], w1*pooled[1], w2*pooled[2], w3*pooled[3]])`

#### 代码实现
```python
# WaveletPacketAttentionPooling.forward()
pooled_list = []
for i, feat in enumerate(wp_features):
    # 1. 频段内注意力池化
    attn_weights = F.softmax(self.attention(feat), dim=1)
    pooled = (feat * attn_weights).sum(dim=1)  # [B*N, C]
    
    # 2. 应用可学习节点权重
    pooled_list.append(pooled * self.node_weights[i])

# 3. 多频段融合（平均）
final_pooled = torch.stack(pooled_list, dim=1).mean(dim=1)  # [B*N, C]
```

## 数据维度变化

```
[B, N, L] 
    ↓ WPD
[B, N, L/4] × 4 个频段
    ↓ 投影
[B*N, L/4, C] × 4
    ↓ 编码+池化
[B, N, C]
```

## 核心问题解答

### Q1: 频段 0,1,2,3 的数量是如何确定的？

**答案**: 通过 `wp_level` 参数确定，公式为 `num_wp_nodes = 2 ** wp_level`

- **默认配置**: `wp_level = 2` → 产生 `2^2 = 4` 个频段
- **原理**: 小波包分解是递归的二叉树结构
  - 每次分解，每个节点分成 2 个子节点（低频 cA 和高频 cD）
  - Level 1: 1 → 2 个节点
  - Level 2: 2 → 4 个节点（频段 0, 1, 2, 3）
  - Level 3: 4 → 8 个节点（如果设置 wp_level=3）
- **代码位置**: `models/T3Time小波包分解版本.py:139`
  ```python
  num_wp_nodes = 2 ** wp_level  # wp_level=2 → 4个频段
  ```

### Q3: 这些参数是手动设定的吗？

**答案**: 是的，这些参数是**手动设定**的，但可以通过多种方式修改：

#### 1. **模型定义中的默认值**（代码第112-113行）
```python
def __init__(
    ...
    wavelet='db4',      # 默认小波基函数
    wp_level=2         # 默认分解层数，产生4个频段
):
```

#### 2. **训练脚本中的命令行参数**（`train_wavelet_packet_gated_qwen.py`）
```bash
# 可以通过命令行参数修改
python train_wavelet_packet_gated_qwen.py \
    --wavelet db4 \        # 可选: db4, haar, coif2 等
    --wp_level 2           # 可选: 1→2个频段, 2→4个频段, 3→8个频段
```

#### 3. **代码中直接传入**
```python
model = TriModalWaveletPacketGatedQwen(
    ...
    wavelet='haar',    # 手动指定小波基
    wp_level=3         # 手动指定分解层数（产生8个频段）
)
```

#### 参数说明

| 参数 | 默认值 | 可选值 | 说明 |
|------|--------|--------|------|
| `wavelet` | `'db4'` | `'db4'`, `'haar'`, `'coif2'`, `'bior2.2'` 等 | 小波基函数类型，影响分解特性 |
| `wp_level` | `2` | `1`, `2`, `3`, `4` 等 | 分解层数，决定频段数量（2^level） |

#### 参数选择建议

- **`wp_level=2`** (4个频段): 平衡性能和复杂度，适合大多数场景
- **`wp_level=3`** (8个频段): 更精细的频段划分，但计算量增加
- **`wavelet='db4'`**: Daubechies 4，在时频分析中常用，平衡性好

### Q2: 后面它们是如何进行融合的？

**答案**: 通过 `WaveletPacketAttentionPooling` 进行三层融合

1. **频段内融合**: 对每个频段内部进行注意力池化，得到每个频段的特征向量
2. **频段权重**: 应用可学习的节点权重 `node_weights[i]`，学习不同频段的重要性
3. **多频段融合**: 使用平均池化融合所有频段的特征
   ```python
   final = mean([w0*pooled[0], w1*pooled[1], w2*pooled[2], w3*pooled[3]])
   ```

**融合公式**:
```
最终特征 = Mean(Σ(频段i的注意力池化结果 × node_weights[i]))
         i=0,1,2,3
```

## Level=3 的特殊说明

### ⚠️ 重要澄清

**Level=3 不会产生"低频、中频、高频"三个频段！**

小波包分解是**二叉树结构**，每次分解都是分成**低频（cA）和高频（cD）**两部分：

- **Level=3** → 产生 **2^3 = 8 个频段**
- 8个频段的频率范围（从低到高）：
  ```
  频段0(最低频) → 频段1 → 频段2 → 频段3 → 频段4 → 频段5 → 频段6 → 频段7(最高频)
  ```

### Level=3 的分解树

```
原始信号
    │
    ├─ Level 1: cA (低频)
    │   ├─ Level 2: cA-cA
    │   │   ├─ Level 3: cA-cA-cA (频段0, 最低频)
    │   │   └─ Level 3: cA-cA-cD (频段1)
    │   └─ Level 2: cA-cD
    │       ├─ Level 3: cA-cD-cA (频段2)
    │       └─ Level 3: cA-cD-cD (频段3)
    │
    └─ Level 1: cD (高频)
        ├─ Level 2: cD-cA
        │   ├─ Level 3: cD-cA-cA (频段4)
        │   └─ Level 3: cD-cA-cD (频段5)
        └─ Level 2: cD-cD
            ├─ Level 3: cD-cD-cA (频段6)
            └─ Level 3: cD-cD-cD (频段7, 最高频)
```

### Level=3 的融合

8个频段经过相同的处理流程：
1. 独立投影（8个投影层）
2. 频段位置编码（8个位置编码）
3. 编码器处理
4. 注意力池化（8个频段各自池化）
5. 可学习权重（8个 node_weights）
6. 平均融合：`final = mean([w0×pooled[0], w1×pooled[1], ..., w7×pooled[7]])`

详细说明请参考：`Level3小波包分解详细说明.md`

## 优势

✓ **精细频段划分**: 同时分解低频和高频部分  
✓ **独立特征学习**: 每个频段独立投影  
✓ **自适应权重**: 可学习频段重要性（node_weights）  
✓ **注意力机制**: 关注重要时间点（频段内注意力池化）  
✓ **灵活融合**: 三层融合机制（频段内 + 权重 + 多频段）  
✓ **可扩展性**: 通过调整 Level 控制频段数量（2^level）
