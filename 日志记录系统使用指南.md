# 实验日志记录系统使用指南

## 概述

这是一个结构化的实验日志记录系统，用于统一记录和管理机器学习/深度学习实验的结果。系统采用 JSONL（每行一个 JSON 对象）格式存储日志，便于后续分析和处理。

## 核心特性

1. **统一格式**: 所有实验结果以 JSON 格式记录到单一文件
2. **结构化存储**: 包含实验配置、超参数、结果指标等完整信息
3. **易于分析**: JSONL 格式便于使用 Python、pandas 等工具进行分析
4. **自动时间戳**: 自动记录实验完成时间
5. **控制台输出**: 同时输出到文件和控制台，方便实时查看

## 文件结构

```
项目根目录/
├── utils/
│   └── experiment_logger.py    # 核心日志记录模块
├── experiment_results.log      # 日志文件（自动生成）
└── train.py                    # 训练脚本示例
```

## 快速开始

### 步骤 1: 创建日志记录模块

在项目的 `utils` 目录下创建 `experiment_logger.py` 文件：

```python
"""
实验结果日志记录工具
统一记录所有实验的结果到 experiment_results.log
"""
import os
import json
from datetime import datetime


def log_experiment_result(
    data_path: str,
    pred_len: int,
    model_name: str,
    seed: int,
    test_mse: float,
    test_mae: float,
    embed_version: str = None,
    seq_len: int = None,
    channel: int = None,
    batch_size: int = None,
    learning_rate: float = None,
    dropout_n: float = None,
    additional_info: dict = None
):
    """
    将实验结果追加到统一的日志文件
    
    Args:
        data_path: 数据集名称（如 ETTh1）
        pred_len: 预测长度
        model_name: 模型名称（如 T3Time, T3Time_Wavelet_Qwen）
        seed: 随机种子
        test_mse: 测试集 MSE
        test_mae: 测试集 MAE
        embed_version: 嵌入版本（如 original, qwen3_0.6b）
        seq_len: 输入序列长度
        channel: 通道数
        batch_size: 批次大小
        learning_rate: 学习率
        dropout_n: Dropout 率
        additional_info: 其他额外信息（字典格式）
    """
    log_file = "./experiment_results.log"
    
    # 构建结果字典
    result = {
        "data_path": data_path,
        "pred_len": pred_len,
        "test_mse": round(test_mse, 6),
        "test_mae": round(test_mae, 6),
        "model": model_name,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "seed": seed,
    }
    
    # 添加可选字段
    if embed_version is not None:
        result["embed_version"] = embed_version
    if seq_len is not None:
        result["seq_len"] = seq_len
    if channel is not None:
        result["channel"] = channel
    if batch_size is not None:
        result["batch_size"] = batch_size
    if learning_rate is not None:
        result["learning_rate"] = learning_rate
    if dropout_n is not None:
        result["dropout_n"] = dropout_n
    if additional_info:
        result.update(additional_info)
    
    # 追加写入日志文件
    with open(log_file, "a", encoding="utf-8") as f:
        # 使用 JSON 格式，每行一个结果
        f.write(json.dumps(result, ensure_ascii=False) + "\n")
    
    # 同时打印到控制台
    print(f"\n{'='*60}")
    print(f"实验结果已记录到: {log_file}")
    print(f"数据集: {data_path}, 预测长度: {pred_len}")
    print(f"Test MSE: {test_mse:.6f}, Test MAE: {test_mae:.6f}")
    print(f"模型: {model_name}, 种子: {seed}")
    if channel: print(f"Channel: {channel}", end=", ")
    if embed_version: print(f"Embed: {embed_version}", end=", ")
    if learning_rate: print(f"LR: {learning_rate}")
    else: print()
    print(f"{'='*60}\n")
```

### 步骤 2: 在训练脚本中使用

在训练脚本中导入并使用日志记录功能：

```python
from utils.experiment_logger import log_experiment_result

# ... 训练代码 ...

# 在训练完成后，记录实验结果
log_experiment_result(
    data_path=args.data_path,
    pred_len=args.pred_len,
    model_name="YourModelName",
    seed=args.seed,
    test_mse=final_test_mse,
    test_mae=final_test_mae,
    embed_version=args.embed_version,
    seq_len=args.seq_len,
    channel=args.channel,
    batch_size=args.batch_size,
    learning_rate=args.learning_rate,
    dropout_n=args.dropout_n,
    additional_info={"custom_param": "custom_value"}  # 可选：添加自定义字段
)
```

### 步骤 3: 自定义字段

如果需要记录项目特定的字段，可以通过 `additional_info` 参数传递：

```python
log_experiment_result(
    data_path="ETTh1",
    pred_len=96,
    model_name="MyModel",
    seed=2024,
    test_mse=0.38,
    test_mae=0.40,
    additional_info={
        "num_layers": 3,
        "hidden_dim": 128,
        "optimizer": "AdamW",
        "scheduler": "CosineAnnealing",
        "custom_metric": 0.95
    }
)
```

## 日志文件格式

日志文件 `experiment_results.log` 采用 JSONL 格式，每行一个 JSON 对象：

```json
{"data_path": "ETTh1", "pred_len": 96, "test_mse": 0.380909, "test_mae": 0.405579, "model": "T3Time", "timestamp": "2025-12-18 14:15:27", "seed": 2024, "embed_version": "qwen3_0.6b", "seq_len": 96, "channel": 32, "batch_size": 16, "learning_rate": 0.0001, "dropout_n": 0.2}
{"data_path": "ETTh1", "pred_len": 192, "test_mse": 0.425123, "test_mae": 0.445678, "model": "T3Time", "timestamp": "2025-12-18 15:20:10", "seed": 2024, "seq_len": 96, "channel": 64, "batch_size": 32, "learning_rate": 0.0001}
```

## 日志分析示例

### 使用 Python 读取日志

```python
import json

def load_logs(log_file="experiment_results.log"):
    """加载 JSONL 格式的日志文件"""
    data = []
    with open(log_file, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data.append(json.loads(line.strip()))
            except json.JSONDecodeError:
                continue
    return data

# 读取所有日志
logs = load_logs()

# 筛选特定数据集的结果
etth1_logs = [log for log in logs if log['data_path'] == 'ETTh1']

# 找到最佳结果
best_result = min(etth1_logs, key=lambda x: x['test_mse'])
print(f"最佳 MSE: {best_result['test_mse']}")
print(f"对应配置: {best_result}")
```

### 使用 pandas 分析

```python
import pandas as pd
import json

def load_logs_to_dataframe(log_file="experiment_results.log"):
    """将日志文件加载为 pandas DataFrame"""
    data = []
    with open(log_file, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data.append(json.loads(line.strip()))
            except json.JSONDecodeError:
                continue
    return pd.DataFrame(data)

# 加载为 DataFrame
df = load_logs_to_dataframe()

# 按数据集和预测长度分组，找到最佳结果
best_results = df.groupby(['data_path', 'pred_len']).apply(
    lambda x: x.loc[x['test_mse'].idxmin()]
)

# 查看统计信息
print(df.groupby('model')['test_mse'].agg(['mean', 'std', 'min', 'max']))
```

### 筛选和查询示例

```python
import json

def filter_logs(log_file, filters):
    """
    根据条件筛选日志
    
    Args:
        log_file: 日志文件路径
        filters: 筛选条件字典，如 {'data_path': 'ETTh1', 'pred_len': 96}
    
    Returns:
        筛选后的日志列表
    """
    results = []
    with open(log_file, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                log = json.loads(line.strip())
                match = all(log.get(k) == v for k, v in filters.items())
                if match:
                    results.append(log)
            except json.JSONDecodeError:
                continue
    return results

# 示例：查找 ETTh1 数据集，预测长度为 96 的所有结果
results = filter_logs('experiment_results.log', {
    'data_path': 'ETTh1',
    'pred_len': 96
})

# 按 MSE 排序
results.sort(key=lambda x: x['test_mse'])
print(f"找到 {len(results)} 条结果")
print(f"最佳 MSE: {results[0]['test_mse']}")
```

## 高级功能扩展

### 1. 支持多个指标

修改 `log_experiment_result` 函数以支持更多指标：

```python
def log_experiment_result(
    # ... 原有参数 ...
    test_rmse: float = None,
    test_mape: float = None,
    test_r2: float = None,
    # ... 其他参数 ...
):
    result = {
        # ... 原有字段 ...
    }
    
    if test_rmse is not None:
        result["test_rmse"] = round(test_rmse, 6)
    if test_mape is not None:
        result["test_mape"] = round(test_mape, 6)
    if test_r2 is not None:
        result["test_r2"] = round(test_r2, 6)
    
    # ... 其余代码 ...
```

### 2. 支持训练过程记录

如果需要记录每个 epoch 的结果，可以创建另一个函数：

```python
def log_epoch_result(
    epoch: int,
    train_loss: float,
    val_loss: float,
    train_mae: float,
    val_mae: float,
    experiment_id: str = None
):
    """记录每个 epoch 的训练结果"""
    log_file = "./training_logs.jsonl"
    
    result = {
        "epoch": epoch,
        "train_loss": round(train_loss, 6),
        "val_loss": round(val_loss, 6),
        "train_mae": round(train_mae, 6),
        "val_mae": round(val_mae, 6),
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    }
    
    if experiment_id:
        result["experiment_id"] = experiment_id
    
    with open(log_file, "a", encoding="utf-8") as f:
        f.write(json.dumps(result, ensure_ascii=False) + "\n")
```

### 3. 支持实验 ID 追踪

为每次实验分配唯一 ID，便于追踪：

```python
import uuid

def log_experiment_result(
    # ... 原有参数 ...
    experiment_id: str = None,
    # ... 其他参数 ...
):
    if experiment_id is None:
        experiment_id = str(uuid.uuid4())[:8]
    
    result = {
        "experiment_id": experiment_id,
        # ... 其他字段 ...
    }
    # ... 其余代码 ...
```

### 4. 日志文件管理

添加日志文件轮转功能，避免单个文件过大：

```python
import os
from datetime import datetime

def get_log_file():
    """获取日志文件路径，支持按日期分割"""
    base_dir = "./logs"
    os.makedirs(base_dir, exist_ok=True)
    
    today = datetime.now().strftime("%Y-%m-%d")
    log_file = os.path.join(base_dir, f"experiment_results_{today}.log")
    return log_file

# 在 log_experiment_result 中使用
log_file = get_log_file()
```

## 完整示例：训练脚本集成

```python
import torch
import argparse
from utils.experiment_logger import log_experiment_result

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_path", type=str, default="ETTh1")
    parser.add_argument("--pred_len", type=int, default=96)
    parser.add_argument("--model_name", type=str, default="MyModel")
    parser.add_argument("--seed", type=int, default=2024)
    parser.add_argument("--seq_len", type=int, default=96)
    parser.add_argument("--channel", type=int, default=32)
    parser.add_argument("--batch_size", type=int, default=16)
    parser.add_argument("--learning_rate", type=float, default=1e-4)
    parser.add_argument("--dropout_n", type=float, default=0.2)
    return parser.parse_args()

def train_model(args):
    # ... 训练代码 ...
    
    # 训练完成后，计算测试集指标
    test_mse = 0.38  # 从实际测试中获取
    test_mae = 0.40  # 从实际测试中获取
    
    # 记录实验结果
    log_experiment_result(
        data_path=args.data_path,
        pred_len=args.pred_len,
        model_name=args.model_name,
        seed=args.seed,
        test_mse=test_mse,
        test_mae=test_mae,
        seq_len=args.seq_len,
        channel=args.channel,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate,
        dropout_n=args.dropout_n,
        additional_info={
            "epochs": 100,
            "early_stopping": True,
            "best_epoch": 85
        }
    )

if __name__ == "__main__":
    args = parse_args()
    train_model(args)
```

## 最佳实践

1. **统一命名**: 确保模型名称、数据集名称等字段在整个项目中保持一致
2. **完整记录**: 记录所有可能影响结果的超参数
3. **及时记录**: 在实验完成后立即记录，避免遗漏
4. **版本控制**: 将 `experiment_logger.py` 纳入版本控制，但将 `experiment_results.log` 添加到 `.gitignore`
5. **定期备份**: 定期备份日志文件，避免数据丢失
6. **日志分析**: 定期分析日志，识别最佳配置和趋势

## 故障排除

### 问题 1: 日志文件不存在

**解决方案**: 日志文件会在首次调用 `log_experiment_result` 时自动创建。如果遇到权限问题，确保对目录有写权限。

### 问题 2: JSON 编码错误

**解决方案**: 确保所有字符串字段使用 UTF-8 编码，避免特殊字符。代码中已使用 `ensure_ascii=False` 和 `encoding="utf-8"`。

### 问题 3: 日志文件过大

**解决方案**: 实现日志文件轮转功能（参考"高级功能扩展"部分），或定期归档旧日志。

### 问题 4: 并发写入问题

**解决方案**: 如果多个进程同时写入，考虑使用文件锁或使用数据库存储。

## 总结

这个日志记录系统提供了：

- ✅ 简单易用的 API
- ✅ 结构化的数据存储
- ✅ 易于分析和查询
- ✅ 可扩展的架构
- ✅ 自动时间戳记录
- ✅ 控制台和文件双重输出

通过遵循本指南，您可以轻松地将此日志记录系统集成到任何机器学习项目中，实现实验结果的统一管理和分析。
