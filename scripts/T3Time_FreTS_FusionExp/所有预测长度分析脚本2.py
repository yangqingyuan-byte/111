#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€ç´¢ T3Time_FreTS_FusionExp æ¨¡å‹çš„æ‰€æœ‰ç§å­çš„å‚æ•°å¯»ä¼˜å®éªŒç»“æœ
æŒ‰é¢„æµ‹é•¿åº¦ï¼ˆ96, 192, 336, 720ï¼‰åˆ†åˆ«åˆ†æ
æ”¯æŒåˆ†ææ‰€æœ‰ç§å­æˆ–æŒ‡å®šç§å­çš„å®éªŒç»“æœ
"""
import json
import os
import sys
from collections import defaultdict
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

def load_hyperopt_results(result_file=None, seed=None, model_id=None, model=None, 
                          model_id_prefix=None, data_path=None):
    """
    åŠ è½½å‚æ•°å¯»ä¼˜å®éªŒç»“æœ
    
    Args:
        result_file: ç»“æœæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º experiment_results.log
        seed: éšæœºç§å­ï¼Œå¦‚æœä¸º None åˆ™åŠ è½½æ‰€æœ‰ç§å­çš„ç»“æœ
        model_id: ç²¾ç¡®åŒ¹é…çš„model_idï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        model: ç²¾ç¡®åŒ¹é…çš„modelåç§°
        model_id_prefix: æ¨¡å‹IDå‰ç¼€ï¼ˆå¦‚æœmodel_idå’Œmodeléƒ½ä¸ºNoneæ—¶ä½¿ç”¨ï¼‰
        data_path: æ•°æ®é›†åç§°ï¼ˆä¾‹å¦‚ 'ETTh1'ï¼‰ã€‚å¦‚æœä¸º None åˆ™ä¸è¿‡æ»¤æ•°æ®é›†ã€‚
    """
    if result_file is None:
        result_file = os.path.join(project_root, "experiment_results.log")
    
    results = []
    
    if not os.path.exists(result_file):
        print(f"âŒ ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {result_file}")
        return results
    
    with open(result_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            if not line.strip():
                continue
            try:
                data = json.loads(line.strip())
                
                # æ¨¡å‹åŒ¹é…é€»è¾‘ï¼ˆä¼˜å…ˆçº§ï¼šmodel_id > model > model_id_prefixï¼‰
                matched = False
                if model_id is not None:
                    # ç²¾ç¡®åŒ¹é…model_id
                    if data.get('model_id') == model_id:
                        matched = True
                elif model is not None:
                    # ç²¾ç¡®åŒ¹é…model
                    if data.get('model') == model:
                        matched = True
                elif model_id_prefix is not None:
                    # å‰ç¼€åŒ¹é…model_id
                    if data.get('model_id', '').startswith(model_id_prefix):
                        matched = True
                else:
                    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•åŒ¹é…æ¡ä»¶ï¼ŒåŒ¹é…æ‰€æœ‰
                    matched = True
                
                if not matched:
                    continue

                # å¦‚æœæŒ‡å®šäº†æ•°æ®é›†ï¼Œåˆ™åªä¿ç•™è¯¥æ•°æ®é›†çš„ç»“æœ
                if data_path is not None:
                    # éƒ¨åˆ†æ—¥å¿—å¯èƒ½ä½¿ç”¨ 'data' æˆ– 'data_path' ä½œä¸ºé”®ï¼Œè¿™é‡Œç»Ÿä¸€å…¼å®¹
                    log_data_path = data.get('data_path', data.get('data'))
                    if log_data_path != data_path:
                        continue

                # å¦‚æœæŒ‡å®šäº† seedï¼Œåˆ™åªåŠ è½½è¯¥ seed çš„ç»“æœï¼›å¦åˆ™åŠ è½½æ‰€æœ‰ seed
                if seed is None or data.get('seed') == seed:
                    results.append(data)
            except json.JSONDecodeError as e:
                continue
            except Exception as e:
                continue
    
    return results

def find_best_params_by_pred_len(results, pred_lens=[96, 192, 336, 720]):
    """æŒ‰é¢„æµ‹é•¿åº¦åˆ†ç»„ï¼Œæ‰¾å‡ºæ¯ä¸ªé¢„æµ‹é•¿åº¦çš„æœ€ä½³å‚æ•°ç»„åˆ"""
    if not results:
        return {}
    
    results_by_pred_len = {}
    
    for pred_len in pred_lens:
        # ç­›é€‰è¯¥é¢„æµ‹é•¿åº¦çš„ç»“æœ
        pred_results = [r for r in results if r.get('pred_len') == pred_len]
        
        if not pred_results:
            results_by_pred_len[pred_len] = {
                'best_mse': None,
                'best_mae': None,
                'sorted_results_mse': [],
                'sorted_results_mae': [],
                'param_avg': {},
                'count': 0
            }
            continue
        
        # æŒ‰ MSE æ’åº
        sorted_results_mse = sorted(pred_results, key=lambda x: x.get('test_mse', float('inf')))
        best_mse = sorted_results_mse[0] if sorted_results_mse else None
        
        # æŒ‰ MAE æ’åº
        sorted_results_mae = sorted(pred_results, key=lambda x: x.get('test_mae', float('inf')))
        best_mae = sorted_results_mae[0] if sorted_results_mae else None
        
        # ç»Ÿè®¡æ¯ä¸ªå‚æ•°ç»„åˆçš„MSEå’ŒMAE
        param_stats_mse = defaultdict(list)
        param_stats_mae = defaultdict(list)
        for r in pred_results:
            param_key = (r.get('channel'), r.get('dropout_n'), r.get('head'))
            param_stats_mse[param_key].append(r.get('test_mse', float('inf')))
            param_stats_mae[param_key].append(r.get('test_mae', float('inf')))
        
        # è®¡ç®—æ¯ä¸ªå‚æ•°ç»„åˆçš„å¹³å‡ MSE å’Œ MAE
        param_avg = {}
        for param_key in param_stats_mse.keys():
            mse_list = param_stats_mse[param_key]
            mae_list = param_stats_mae[param_key]
            param_avg[param_key] = {
                'mse_mean': sum(mse_list) / len(mse_list),
                'mse_min': min(mse_list),
                'mse_max': max(mse_list),
                'mae_mean': sum(mae_list) / len(mae_list),
                'mae_min': min(mae_list),
                'mae_max': max(mae_list),
                'count': len(mse_list)
            }
        
        results_by_pred_len[pred_len] = {
            'best_mse': best_mse,
            'best_mae': best_mae,
            'sorted_results_mse': sorted_results_mse,
            'sorted_results_mae': sorted_results_mae,
            'param_avg': param_avg,
            'count': len(pred_results)
        }
    
    return results_by_pred_len

def get_available_models(result_file=None):
    """
    ä»æ—¥å¿—æ–‡ä»¶ä¸­æå–æ‰€æœ‰å¯ç”¨çš„model_idå’Œmodel
    
    Args:
        result_file: ç»“æœæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º experiment_results.log
    
    Returns:
        tuple: (model_idsåˆ—è¡¨, modelsåˆ—è¡¨)ï¼Œéƒ½æŒ‰å­—æ¯é¡ºåºæ’åº
    """
    if result_file is None:
        result_file = os.path.join(project_root, "experiment_results.log")
    
    model_ids = set()
    models = set()
    
    if not os.path.exists(result_file):
        return [], []
    
    with open(result_file, 'r', encoding='utf-8') as f:
        for line in f:
            if not line.strip():
                continue
            try:
                data = json.loads(line.strip())
                # æå–model_id
                model_id = data.get('model_id')
                if model_id:
                    model_ids.add(model_id)
                # æå–model
                model = data.get('model')
                if model:
                    models.add(model)
            except (json.JSONDecodeError, Exception):
                continue
    
    return sorted(list(model_ids)), sorted(list(models))

def get_available_datasets(result_file=None, model_id=None, model=None, model_id_prefix=None):
    """
    ä»æ—¥å¿—æ–‡ä»¶ä¸­æå–æ‰€æœ‰å¯ç”¨çš„æ•°æ®é›†
    
    Args:
        result_file: ç»“æœæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º experiment_results.log
        model_id: ç²¾ç¡®åŒ¹é…çš„model_id
        model: ç²¾ç¡®åŒ¹é…çš„modelåç§°
        model_id_prefix: æ¨¡å‹IDå‰ç¼€
    
    Returns:
        list: å¯ç”¨æ•°æ®é›†åˆ—è¡¨ï¼ŒæŒ‰å­—æ¯é¡ºåºæ’åº
    """
    if result_file is None:
        result_file = os.path.join(project_root, "experiment_results.log")
    
    datasets = set()
    
    if not os.path.exists(result_file):
        return []
    
    with open(result_file, 'r', encoding='utf-8') as f:
        for line in f:
            if not line.strip():
                continue
            try:
                data = json.loads(line.strip())
                
                # æ¨¡å‹åŒ¹é…é€»è¾‘
                matched = False
                if model_id is not None:
                    if data.get('model_id') == model_id:
                        matched = True
                elif model is not None:
                    if data.get('model') == model:
                        matched = True
                elif model_id_prefix is not None:
                    if data.get('model_id', '').startswith(model_id_prefix):
                        matched = True
                else:
                    matched = True
                
                if not matched:
                    continue
                
                # æå–æ•°æ®é›†åç§°
                data_path = data.get('data_path', data.get('data'))
                if data_path:
                    datasets.add(data_path)
            except (json.JSONDecodeError, Exception):
                continue
    
    return sorted(list(datasets))

def interactive_select_model(result_file=None):
    """
    äº¤äº’å¼é€‰æ‹©æ¨¡å‹ï¼ˆmodel_idæˆ–modelï¼‰
    
    Args:
        result_file: ç»“æœæ–‡ä»¶è·¯å¾„
    
    Returns:
        tuple: (model_id, model, model_id_prefix)ï¼Œå¦‚æœç”¨æˆ·å–æ¶ˆåˆ™è¿”å› (None, None, None)
    """
    model_ids, models = get_available_models(result_file)
    
    if not model_ids and not models:
        print("\nâŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æ¨¡å‹")
        return None, None, None
    
    print("\n" + "="*80)
    print("ğŸ” è¯·é€‰æ‹©è¦æ£€ç´¢çš„æ¨¡å‹")
    print("="*80)
    print("\né€‰æ‹©æ–¹å¼:")
    print("  [1] é€šè¿‡ model_id æ£€ç´¢")
    print("  [2] é€šè¿‡ model åç§°æ£€ç´¢")
    print("  [3] é€šè¿‡ model_id å‰ç¼€æ£€ç´¢")
    print("  [4] æ‰‹åŠ¨è¾“å…¥ model_id æˆ– model")
    print("  [0] å–æ¶ˆ")
    print("-"*80)
    
    while True:
        try:
            choice = input("\nè¯·é€‰æ‹©æ–¹å¼ (0-4): ").strip()
            
            if choice == '0':
                print("å·²å–æ¶ˆé€‰æ‹©")
                return None, None, None
            
            elif choice == '1':
                # é€šè¿‡model_idæ£€ç´¢
                if not model_ids:
                    print("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„ model_id")
                    continue
                
                print("\nå¯ç”¨çš„ model_id:")
                print("-"*80)
                for idx, mid in enumerate(model_ids, 1):
                    print(f"  [{idx}] {mid}")
                print("  [0] è¿”å›")
                print("-"*80)
                
                sub_choice = input("\nè¯·è¾“å…¥é€‰é¡¹ç¼–å· (0-{}): ".format(len(model_ids))).strip()
                if sub_choice == '0':
                    continue
                
                try:
                    sub_choice_num = int(sub_choice)
                    if 1 <= sub_choice_num <= len(model_ids):
                        selected = model_ids[sub_choice_num - 1]
                        print(f"\nâœ“ å·²é€‰æ‹© model_id: {selected}")
                        return selected, None, None
                    else:
                        print(f"âŒ æ— æ•ˆçš„é€‰é¡¹")
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            
            elif choice == '2':
                # é€šè¿‡modelæ£€ç´¢
                if not models:
                    print("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„ model")
                    continue
                
                print("\nå¯ç”¨çš„ model:")
                print("-"*80)
                for idx, m in enumerate(models, 1):
                    print(f"  [{idx}] {m}")
                print("  [0] è¿”å›")
                print("-"*80)
                
                sub_choice = input("\nè¯·è¾“å…¥é€‰é¡¹ç¼–å· (0-{}): ".format(len(models))).strip()
                if sub_choice == '0':
                    continue
                
                try:
                    sub_choice_num = int(sub_choice)
                    if 1 <= sub_choice_num <= len(models):
                        selected = models[sub_choice_num - 1]
                        print(f"\nâœ“ å·²é€‰æ‹© model: {selected}")
                        return None, selected, None
                    else:
                        print(f"âŒ æ— æ•ˆçš„é€‰é¡¹")
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            
            elif choice == '3':
                # é€šè¿‡model_idå‰ç¼€æ£€ç´¢
                if not model_ids:
                    print("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„ model_id")
                    continue
                
                print("\nå¯ç”¨çš„ model_id å‰ç¼€ï¼ˆåŸºäºç°æœ‰model_idï¼‰:")
                print("-"*80)
                # æå–å‰ç¼€
                prefixes = set()
                for mid in model_ids:
                    parts = mid.split('_')
                    for i in range(1, len(parts) + 1):
                        prefixes.add('_'.join(parts[:i]))
                
                prefixes = sorted(list(prefixes))
                for idx, prefix in enumerate(prefixes, 1):
                    print(f"  [{idx}] {prefix}")
                print("  [0] è¿”å›")
                print("-"*80)
                
                sub_choice = input("\nè¯·è¾“å…¥é€‰é¡¹ç¼–å· (0-{}): ".format(len(prefixes))).strip()
                if sub_choice == '0':
                    continue
                
                try:
                    sub_choice_num = int(sub_choice)
                    if 1 <= sub_choice_num <= len(prefixes):
                        selected = prefixes[sub_choice_num - 1]
                        print(f"\nâœ“ å·²é€‰æ‹© model_id å‰ç¼€: {selected}")
                        return None, None, selected
                    else:
                        print(f"âŒ æ— æ•ˆçš„é€‰é¡¹")
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            
            elif choice == '4':
                # æ‰‹åŠ¨è¾“å…¥
                print("\nè¯·è¾“å…¥ model_id æˆ– model åç§°ï¼ˆç•™ç©ºåˆ™æ£€ç´¢æ‰€æœ‰ï¼‰:")
                user_input = input("> ").strip()
                
                if not user_input:
                    print("\nâœ“ å°†æ£€ç´¢æ‰€æœ‰æ¨¡å‹")
                    return None, None, None
                
                # æ£€æŸ¥æ˜¯model_idè¿˜æ˜¯model
                if user_input in model_ids:
                    print(f"\nâœ“ å·²é€‰æ‹© model_id: {user_input}")
                    return user_input, None, None
                elif user_input in models:
                    print(f"\nâœ“ å·²é€‰æ‹© model: {user_input}")
                    return None, user_input, None
                else:
                    # å°è¯•ä½œä¸ºå‰ç¼€
                    matching_ids = [mid for mid in model_ids if mid.startswith(user_input)]
                    matching_models = [m for m in models if m.startswith(user_input)]
                    
                    if matching_ids:
                        print(f"\næ‰¾åˆ°åŒ¹é…çš„ model_id: {matching_ids[0]}")
                        print(f"âœ“ å·²é€‰æ‹© model_id: {matching_ids[0]}")
                        return matching_ids[0], None, None
                    elif matching_models:
                        print(f"\næ‰¾åˆ°åŒ¹é…çš„ model: {matching_models[0]}")
                        print(f"âœ“ å·²é€‰æ‹© model: {matching_models[0]}")
                        return None, matching_models[0], None
                    else:
                        print(f"\nâš  æœªæ‰¾åˆ°ç²¾ç¡®åŒ¹é…ï¼Œå°†ä½œä¸ºå‰ç¼€ä½¿ç”¨: {user_input}")
                        print(f"âœ“ å·²é€‰æ‹© model_id å‰ç¼€: {user_input}")
                        return None, None, user_input
            
            else:
                print("âŒ æ— æ•ˆçš„é€‰é¡¹ï¼Œè¯·è¾“å…¥ 0-4 ä¹‹é—´çš„æ•°å­—")
        
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\n\nå·²å–æ¶ˆé€‰æ‹©")
            return None, None, None

def interactive_select_dataset(result_file=None, model_id=None, model=None, model_id_prefix=None):
    """
    äº¤äº’å¼é€‰æ‹©æ•°æ®é›†
    
    Args:
        result_file: ç»“æœæ–‡ä»¶è·¯å¾„
        model_id: ç²¾ç¡®åŒ¹é…çš„model_id
        model: ç²¾ç¡®åŒ¹é…çš„modelåç§°
        model_id_prefix: æ¨¡å‹IDå‰ç¼€
    
    Returns:
        str: ç”¨æˆ·é€‰æ‹©çš„æ•°æ®é›†åç§°ï¼Œå¦‚æœç”¨æˆ·å–æ¶ˆåˆ™è¿”å› None
    """
    datasets = get_available_datasets(result_file, model_id, model, model_id_prefix)
    
    if not datasets:
        print("\nâŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æ•°æ®é›†")
        return None
    
    print("\n" + "="*80)
    print("ğŸ“Š è¯·é€‰æ‹©è¦åˆ†æçš„æ•°æ®é›†")
    print("="*80)
    print("\nå¯ç”¨çš„æ•°æ®é›†:")
    print("-"*80)
    
    for idx, dataset in enumerate(datasets, 1):
        print(f"  [{idx}] {dataset}")
    
    print(f"  [0] å–æ¶ˆ")
    print("-"*80)
    
    while True:
        try:
            choice = input("\nè¯·è¾“å…¥é€‰é¡¹ç¼–å· (0-{}): ".format(len(datasets))).strip()
            
            if choice == '0':
                print("å·²å–æ¶ˆé€‰æ‹©")
                return None
            
            choice_num = int(choice)
            if 1 <= choice_num <= len(datasets):
                selected = datasets[choice_num - 1]
                print(f"\nâœ“ å·²é€‰æ‹©æ•°æ®é›†: {selected}")
                return selected
            else:
                print(f"âŒ æ— æ•ˆçš„é€‰é¡¹ï¼Œè¯·è¾“å…¥ 0-{len(datasets)} ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\n\nå·²å–æ¶ˆé€‰æ‹©")
            return None

def get_seed_statistics(results):
    """ç»Ÿè®¡æ‰€æœ‰ç»“æœçš„ç§å­åˆ†å¸ƒ"""
    seed_counts = defaultdict(int)
    seed_by_pred_len = defaultdict(lambda: defaultdict(int))
    
    for r in results:
        seed = r.get('seed', 'Unknown')
        pred_len = r.get('pred_len', 'Unknown')
        seed_counts[seed] += 1
        seed_by_pred_len[pred_len][seed] += 1
    
    return seed_counts, seed_by_pred_len

def print_results_by_pred_len(results_by_pred_len, pred_lens=[96, 192, 336, 720], all_results=None, data_path=None):
    """æŒ‰é¢„æµ‹é•¿åº¦æ‰“å°ç»“æœ"""
    print("="*80)
    print("T3Time_FreTS_Gated_Qwen å‚æ•°å¯»ä¼˜ç»“æœåˆ†æï¼ˆæ‰€æœ‰ç§å­ï¼‰")
    if data_path:
        print(f"æ•°æ®é›†: {data_path}")
    print("æŒ‰é¢„æµ‹é•¿åº¦åˆ†åˆ«åˆ†æ: {}".format(", ".join(map(str, pred_lens))))
    print("="*80)
    
    # ç»Ÿè®¡æ€»ç»“æœæ•°å’Œç§å­åˆ†å¸ƒ
    total_results = sum(data['count'] for data in results_by_pred_len.values())
    
    if all_results:
        seed_counts, seed_by_pred_len_stats = get_seed_statistics(all_results)
        print(f"\næ‰¾åˆ° {total_results} æ¡å®éªŒç»“æœ")
        print(f"æ¶‰åŠ {len(seed_counts)} ä¸ªä¸åŒçš„ç§å­: {sorted(seed_counts.keys())}")
        print("\nç§å­åˆ†å¸ƒç»Ÿè®¡:")
        print(f"{'Seed':<10} {'æ€»å®éªŒæ•°':<12}")
        print("-"*25)
        for seed in sorted(seed_counts.keys()):
            print(f"{seed:<10} {seed_counts[seed]:<12}")
    else:
        print(f"\næ‰¾åˆ° {total_results} æ¡å®éªŒç»“æœ\n")
    
    # å¯¹æ¯ä¸ªé¢„æµ‹é•¿åº¦åˆ†åˆ«åˆ†æ
    for pred_len in pred_lens:
        data = results_by_pred_len.get(pred_len, {})
        best_mse = data.get('best_mse')
        best_mae = data.get('best_mae')
        sorted_results_mse = data.get('sorted_results_mse', [])
        sorted_results_mae = data.get('sorted_results_mae', [])
        param_avg = data.get('param_avg', {})
        count = data.get('count', 0)
        
        if not best_mse or not best_mae:
            print("\n" + "="*80)
            print(f"é¢„æµ‹é•¿åº¦ {pred_len}: æœªæ‰¾åˆ°å®éªŒç»“æœ")
            print("="*80)
            continue
        
        print("\n" + "="*80)
        print(f"ğŸ“Š é¢„æµ‹é•¿åº¦ {pred_len} (å…± {count} æ¡å®éªŒç»“æœ)")
        print("="*80)
        
        # æ‰“å°è¯¥é¢„æµ‹é•¿åº¦çš„æœ€ä½³ç»“æœ
        print_single_pred_len_results(best_mse, best_mae, sorted_results_mse, sorted_results_mae, param_avg, pred_len)

def print_single_pred_len_results(best_mse, best_mae, sorted_results_mse, sorted_results_mae, param_avg, pred_len):
    """æ‰“å°å•ä¸ªé¢„æµ‹é•¿åº¦çš„ç»“æœ"""
    
    # æœ€å°MSEæœ€ä½³ç»“æœï¼ˆæ˜¾ç¤ºæ‰€æœ‰è¯¦ç»†å‚æ•°ï¼‰
    print("\n" + "="*80)
    print(f"ğŸ† é¢„æµ‹é•¿åº¦ {pred_len} - æœ€å° MSE å‚æ•°ç»„åˆï¼ˆå®Œæ•´å‚æ•°ï¼‰")
    print("="*80)
    print("ã€æ¶æ„å‚æ•°ã€‘")
    print(f"  Channel:        {best_mse.get('channel', 'N/A')}")
    print(f"  Head:           {best_mse.get('head', 'N/A')}")
    print(f"  E_Layer:        {best_mse.get('e_layer', 'N/A')}")
    print(f"  D_Layer:        {best_mse.get('d_layer', 'N/A')}")
    print("")
    print("ã€è®­ç»ƒå‚æ•°ã€‘")
    print(f"  Learning_Rate:  {best_mse.get('learning_rate', 'N/A')}")
    print(f"  Weight_Decay:   {best_mse.get('weight_decay', 'N/A')}")
    print(f"  Dropout:        {best_mse.get('dropout_n', 'N/A')}")
    print(f"  Batch_Size:     {best_mse.get('batch_size', 'N/A')}")
    print(f"  Loss_Function:  {best_mse.get('loss_fn', 'N/A')}")
    print(f"  LR_Adjust:      {best_mse.get('lradj', 'N/A')}")
    print("")
    print("ã€æ•°æ®å‚æ•°ã€‘")
    print(f"  Data_Path:      {best_mse.get('data_path', 'N/A')}")
    print(f"  Seq_Len:        {best_mse.get('seq_len', 'N/A')}")
    print(f"  Pred_Len:       {best_mse.get('pred_len', 'N/A')}")
    print(f"  Embed_Version:  {best_mse.get('embed_version', 'N/A')}")
    print("")
    print("ã€è®­ç»ƒé…ç½®ã€‘")
    print(f"  Epochs:         {best_mse.get('epochs', 'N/A')}")
    print(f"  Patience:       {best_mse.get('patience', 'N/A')}")
    print(f"  Seed:           {best_mse.get('seed', 'N/A')} â­")
    print("")
    print("ã€ç»“æœæŒ‡æ ‡ã€‘")
    print(f"  Test MSE:       {best_mse.get('test_mse', 'N/A'):.6f}")
    print(f"  Test MAE:       {best_mse.get('test_mae', 'N/A'):.6f}")
    print("")
    print("ã€å…¶ä»–ä¿¡æ¯ã€‘")
    print(f"  Model_ID:       {best_mse.get('model_id', 'N/A')}")
    print(f"  Timestamp:      {best_mse.get('timestamp', 'N/A')}")
    
    # æœ€å°MAEæœ€ä½³ç»“æœï¼ˆæ˜¾ç¤ºæ‰€æœ‰è¯¦ç»†å‚æ•°ï¼‰
    print("\n" + "="*80)
    print(f"ğŸ† é¢„æµ‹é•¿åº¦ {pred_len} - æœ€å° MAE å‚æ•°ç»„åˆï¼ˆå®Œæ•´å‚æ•°ï¼‰")
    print("="*80)
    print("ã€æ¶æ„å‚æ•°ã€‘")
    print(f"  Channel:        {best_mae.get('channel', 'N/A')}")
    print(f"  Head:           {best_mae.get('head', 'N/A')}")
    print(f"  E_Layer:        {best_mae.get('e_layer', 'N/A')}")
    print(f"  D_Layer:        {best_mae.get('d_layer', 'N/A')}")
    print("")
    print("ã€è®­ç»ƒå‚æ•°ã€‘")
    print(f"  Learning_Rate:  {best_mae.get('learning_rate', 'N/A')}")
    print(f"  Weight_Decay:   {best_mae.get('weight_decay', 'N/A')}")
    print(f"  Dropout:        {best_mae.get('dropout_n', 'N/A')}")
    print(f"  Batch_Size:     {best_mae.get('batch_size', 'N/A')}")
    print(f"  Loss_Function:  {best_mae.get('loss_fn', 'N/A')}")
    print(f"  LR_Adjust:      {best_mae.get('lradj', 'N/A')}")
    print("")
    print("ã€æ•°æ®å‚æ•°ã€‘")
    print(f"  Data_Path:      {best_mae.get('data_path', 'N/A')}")
    print(f"  Seq_Len:        {best_mae.get('seq_len', 'N/A')}")
    print(f"  Pred_Len:       {best_mae.get('pred_len', 'N/A')}")
    print(f"  Embed_Version:  {best_mae.get('embed_version', 'N/A')}")
    print("")
    print("ã€è®­ç»ƒé…ç½®ã€‘")
    print(f"  Epochs:         {best_mae.get('epochs', 'N/A')}")
    print(f"  Patience:       {best_mae.get('patience', 'N/A')}")
    print(f"  Seed:           {best_mae.get('seed', 'N/A')} â­")
    print("")
    print("ã€ç»“æœæŒ‡æ ‡ã€‘")
    print(f"  Test MSE:       {best_mae.get('test_mse', 'N/A'):.6f}")
    print(f"  Test MAE:       {best_mae.get('test_mae', 'N/A'):.6f}")
    print("")
    print("ã€å…¶ä»–ä¿¡æ¯ã€‘")
    print(f"  Model_ID:       {best_mae.get('model_id', 'N/A')}")
    print(f"  Timestamp:      {best_mae.get('timestamp', 'N/A')}")
    
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°æ ¼å¼ï¼Œæ–¹ä¾¿ç›´æ¥ä½¿ç”¨
    print("\n" + "="*80)
    print(f"ğŸ“‹ é¢„æµ‹é•¿åº¦ {pred_len} - æœ€ä½³ MSE å‚æ•°ç»„åˆï¼ˆå‘½ä»¤è¡Œæ ¼å¼ï¼‰")
    print("="*80)
    print("python train_frets_gated_qwen.py \\")
    print(f"    --data_path {best_mse.get('data_path', 'ETTh1')} \\")
    print(f"    --seq_len {best_mse.get('seq_len', 96)} \\")
    print(f"    --pred_len {best_mse.get('pred_len', 96)} \\")
    print(f"    --channel {best_mse.get('channel', 'N/A')} \\")
    print(f"    --head {best_mse.get('head', 'N/A')} \\")
    print(f"    --e_layer {best_mse.get('e_layer', 1)} \\")
    print(f"    --d_layer {best_mse.get('d_layer', 1)} \\")
    print(f"    --learning_rate {best_mse.get('learning_rate', 'N/A')} \\")
    print(f"    --weight_decay {best_mse.get('weight_decay', 'N/A')} \\")
    print(f"    --dropout_n {best_mse.get('dropout_n', 'N/A')} \\")
    print(f"    --batch_size {best_mse.get('batch_size', 'N/A')} \\")
    print(f"    --loss_fn {best_mse.get('loss_fn', 'N/A')} \\")
    print(f"    --lradj {best_mse.get('lradj', 'type1')} \\")
    print(f"    --embed_version {best_mse.get('embed_version', 'qwen3_0.6b')} \\")
    print(f"    --epochs {best_mse.get('epochs', 100)} \\")
    print(f"    --es_patience {best_mse.get('patience', 10)} \\")
    print(f"    --seed {best_mse.get('seed', 2088)}")
    
    print("\n" + "="*80)
    print(f"ğŸ“‹ é¢„æµ‹é•¿åº¦ {pred_len} - æœ€ä½³ MAE å‚æ•°ç»„åˆï¼ˆå‘½ä»¤è¡Œæ ¼å¼ï¼‰")
    print("="*80)
    print("python train_frets_gated_qwen.py \\")
    print(f"    --data_path {best_mae.get('data_path', 'ETTh1')} \\")
    print(f"    --seq_len {best_mae.get('seq_len', 96)} \\")
    print(f"    --pred_len {best_mae.get('pred_len', 96)} \\")
    print(f"    --channel {best_mae.get('channel', 'N/A')} \\")
    print(f"    --head {best_mae.get('head', 'N/A')} \\")
    print(f"    --e_layer {best_mae.get('e_layer', 1)} \\")
    print(f"    --d_layer {best_mae.get('d_layer', 1)} \\")
    print(f"    --learning_rate {best_mae.get('learning_rate', 'N/A')} \\")
    print(f"    --weight_decay {best_mae.get('weight_decay', 'N/A')} \\")
    print(f"    --dropout_n {best_mae.get('dropout_n', 'N/A')} \\")
    print(f"    --batch_size {best_mae.get('batch_size', 'N/A')} \\")
    print(f"    --loss_fn {best_mae.get('loss_fn', 'N/A')} \\")
    print(f"    --lradj {best_mae.get('lradj', 'type1')} \\")
    print(f"    --embed_version {best_mae.get('embed_version', 'qwen3_0.6b')} \\")
    print(f"    --epochs {best_mae.get('epochs', 100)} \\")
    print(f"    --es_patience {best_mae.get('patience', 10)} \\")
    print(f"    --seed {best_mae.get('seed', 2088)}")
    
    # Top 10 æœ€ä½³ç»“æœï¼ˆæŒ‰MSEï¼‰
    print("\n" + "="*80)
    print(f"é¢„æµ‹é•¿åº¦ {pred_len} - Top 10 æœ€ä½³é…ç½®ï¼ˆæŒ‰ MSE æ’åºï¼‰")
    print("="*80)
    print(f"{'Rank':<6} {'Channel':<10} {'Dropout':<10} {'Head':<8} {'MSE':<15} {'MAE':<15}")
    print("-"*80)
    
    for i, r in enumerate(sorted_results_mse[:10], 1):
        print(f"{i:<6} {r.get('channel', 'N/A'):<10} {r.get('dropout_n', 'N/A'):<10.1f} "
              f"{r.get('head', 'N/A'):<8} {r.get('test_mse', 'N/A'):<15.6f} {r.get('test_mae', 'N/A'):<15.6f}")
    
    # Top 10 æœ€ä½³ç»“æœï¼ˆæŒ‰MAEï¼‰
    print("\n" + "="*80)
    print(f"é¢„æµ‹é•¿åº¦ {pred_len} - Top 10 æœ€ä½³é…ç½®ï¼ˆæŒ‰ MAE æ’åºï¼‰")
    print("="*80)
    print(f"{'Rank':<6} {'Channel':<10} {'Dropout':<10} {'Head':<8} {'MSE':<15} {'MAE':<15}")
    print("-"*80)
    
    for i, r in enumerate(sorted_results_mae[:10], 1):
        print(f"{i:<6} {r.get('channel', 'N/A'):<10} {r.get('dropout_n', 'N/A'):<10.1f} "
              f"{r.get('head', 'N/A'):<8} {r.get('test_mse', 'N/A'):<15.6f} {r.get('test_mae', 'N/A'):<15.6f}")
    
    # å‚æ•°ç»Ÿè®¡åˆ†æï¼ˆæŒ‰MSEï¼‰
    print("\n" + "="*80)
    print(f"é¢„æµ‹é•¿åº¦ {pred_len} - å‚æ•°ç»Ÿè®¡åˆ†æï¼ˆæŒ‰å¹³å‡ MSE æ’åºï¼‰")
    print("="*80)
    print(f"{'Channel':<10} {'Dropout':<10} {'Head':<8} {'å¹³å‡MSE':<15} {'æœ€å°MSE':<15} {'æœ€å¤§MSE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    
    sorted_params_mse = sorted(param_avg.items(), key=lambda x: x[1]['mse_mean'])
    for (channel, dropout, head), stats in sorted_params_mse[:20]:  # æ˜¾ç¤ºå‰20ä¸ª
        print(f"{channel:<10} {dropout:<10.1f} {head:<8} "
              f"{stats['mse_mean']:<15.6f} {stats['mse_min']:<15.6f} {stats['mse_max']:<15.6f} {stats['count']:<8}")
    
    # å‚æ•°ç»Ÿè®¡åˆ†æï¼ˆæŒ‰MAEï¼‰
    print("\n" + "="*80)
    print(f"é¢„æµ‹é•¿åº¦ {pred_len} - å‚æ•°ç»Ÿè®¡åˆ†æï¼ˆæŒ‰å¹³å‡ MAE æ’åºï¼‰")
    print("="*80)
    print(f"{'Channel':<10} {'Dropout':<10} {'Head':<8} {'å¹³å‡MAE':<15} {'æœ€å°MAE':<15} {'æœ€å¤§MAE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    
    sorted_params_mae = sorted(param_avg.items(), key=lambda x: x[1]['mae_mean'])
    for (channel, dropout, head), stats in sorted_params_mae[:20]:  # æ˜¾ç¤ºå‰20ä¸ª
        print(f"{channel:<10} {dropout:<10.1f} {head:<8} "
              f"{stats['mae_mean']:<15.6f} {stats['mae_min']:<15.6f} {stats['mae_max']:<15.6f} {stats['count']:<8}")
    
    # å„å‚æ•°ç»´åº¦åˆ†æ
    print("\n" + "="*80)
    print(f"é¢„æµ‹é•¿åº¦ {pred_len} - å„å‚æ•°ç»´åº¦åˆ†æï¼ˆMSEï¼‰")
    print("="*80)
    
    # Channel åˆ†æï¼ˆMSEï¼‰
    channel_stats_mse = defaultdict(list)
    channel_stats_mae = defaultdict(list)
    for r in sorted_results_mse:
        channel_stats_mse[r.get('channel')].append(r.get('test_mse', float('inf')))
        channel_stats_mae[r.get('channel')].append(r.get('test_mae', float('inf')))
    
    print("\n[1] Channel å‚æ•°åˆ†æï¼ˆMSEï¼‰:")
    print(f"{'Channel':<10} {'å¹³å‡MSE':<15} {'æœ€å°MSE':<15} {'æœ€å¤§MSE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    for channel in sorted(channel_stats_mse.keys()):
        mse_list = channel_stats_mse[channel]
        print(f"{channel:<10} {sum(mse_list)/len(mse_list):<15.6f} "
              f"{min(mse_list):<15.6f} {max(mse_list):<15.6f} {len(mse_list):<8}")
    
    # Dropout åˆ†æï¼ˆMSEï¼‰
    dropout_stats_mse = defaultdict(list)
    dropout_stats_mae = defaultdict(list)
    for r in sorted_results_mse:
        dropout_stats_mse[r.get('dropout_n')].append(r.get('test_mse', float('inf')))
        dropout_stats_mae[r.get('dropout_n')].append(r.get('test_mae', float('inf')))
    
    print("\n[2] Dropout å‚æ•°åˆ†æï¼ˆMSEï¼‰:")
    print(f"{'Dropout':<10} {'å¹³å‡MSE':<15} {'æœ€å°MSE':<15} {'æœ€å¤§MSE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    for dropout in sorted(dropout_stats_mse.keys()):
        mse_list = dropout_stats_mse[dropout]
        print(f"{dropout:<10.1f} {sum(mse_list)/len(mse_list):<15.6f} "
              f"{min(mse_list):<15.6f} {max(mse_list):<15.6f} {len(mse_list):<8}")
    
    # Head åˆ†æï¼ˆMSEï¼‰
    head_stats_mse = defaultdict(list)
    head_stats_mae = defaultdict(list)
    for r in sorted_results_mse:
        head_stats_mse[r.get('head')].append(r.get('test_mse', float('inf')))
        head_stats_mae[r.get('head')].append(r.get('test_mae', float('inf')))
    
    print("\n[3] Head å‚æ•°åˆ†æï¼ˆMSEï¼‰:")
    print(f"{'Head':<10} {'å¹³å‡MSE':<15} {'æœ€å°MSE':<15} {'æœ€å¤§MSE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    for head in sorted(head_stats_mse.keys()):
        mse_list = head_stats_mse[head]
        print(f"{head:<10} {sum(mse_list)/len(mse_list):<15.6f} "
              f"{min(mse_list):<15.6f} {max(mse_list):<15.6f} {len(mse_list):<8}")
    
    # å„å‚æ•°ç»´åº¦åˆ†æï¼ˆMAEï¼‰
    print("\n" + "="*80)
    print(f"é¢„æµ‹é•¿åº¦ {pred_len} - å„å‚æ•°ç»´åº¦åˆ†æï¼ˆMAEï¼‰")
    print("="*80)
    
    print("\n[1] Channel å‚æ•°åˆ†æï¼ˆMAEï¼‰:")
    print(f"{'Channel':<10} {'å¹³å‡MAE':<15} {'æœ€å°MAE':<15} {'æœ€å¤§MAE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    for channel in sorted(channel_stats_mae.keys()):
        mae_list = channel_stats_mae[channel]
        print(f"{channel:<10} {sum(mae_list)/len(mae_list):<15.6f} "
              f"{min(mae_list):<15.6f} {max(mae_list):<15.6f} {len(mae_list):<8}")
    
    print("\n[2] Dropout å‚æ•°åˆ†æï¼ˆMAEï¼‰:")
    print(f"{'Dropout':<10} {'å¹³å‡MAE':<15} {'æœ€å°MAE':<15} {'æœ€å¤§MAE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    for dropout in sorted(dropout_stats_mae.keys()):
        mae_list = dropout_stats_mae[dropout]
        print(f"{dropout:<10.1f} {sum(mae_list)/len(mae_list):<15.6f} "
              f"{min(mae_list):<15.6f} {max(mae_list):<15.6f} {len(mae_list):<8}")
    
    print("\n[3] Head å‚æ•°åˆ†æï¼ˆMAEï¼‰:")
    print(f"{'Head':<10} {'å¹³å‡MAE':<15} {'æœ€å°MAE':<15} {'æœ€å¤§MAE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    for head in sorted(head_stats_mae.keys()):
        mae_list = head_stats_mae[head]
        print(f"{head:<10} {sum(mae_list)/len(mae_list):<15.6f} "
              f"{min(mae_list):<15.6f} {max(mae_list):<15.6f} {len(mae_list):<8}")
    
    # æœ€ä½³å‚æ•°ç»„åˆï¼ˆæŒ‰å¹³å‡MSEï¼‰
    if param_avg:
        best_param_avg_mse = min(param_avg.items(), key=lambda x: x[1]['mse_mean'])
        (best_channel_mse, best_dropout_mse, best_head_mse), best_stats_mse = best_param_avg_mse
        
        print("\n" + "="*80)
        print(f"é¢„æµ‹é•¿åº¦ {pred_len} - ğŸ† æœ€ä½³å‚æ•°ç»„åˆï¼ˆæŒ‰å¹³å‡ MSEï¼‰")
        print("="*80)
        print(f"Channel:     {best_channel_mse}")
        print(f"Dropout:     {best_dropout_mse}")
        print(f"Head:        {best_head_mse}")
        print(f"å¹³å‡ MSE:    {best_stats_mse['mse_mean']:.6f}")
        print(f"æœ€å° MSE:    {best_stats_mse['mse_min']:.6f}")
        print(f"æœ€å¤§ MSE:    {best_stats_mse['mse_max']:.6f}")
        print(f"å¹³å‡ MAE:    {best_stats_mse['mae_mean']:.6f}")
        print(f"æœ€å° MAE:    {best_stats_mse['mae_min']:.6f}")
        print(f"æœ€å¤§ MAE:    {best_stats_mse['mae_max']:.6f}")
        print(f"å®éªŒæ¬¡æ•°:    {best_stats_mse['count']}")
        
        # æœ€ä½³å‚æ•°ç»„åˆï¼ˆæŒ‰å¹³å‡MAEï¼‰
        best_param_avg_mae = min(param_avg.items(), key=lambda x: x[1]['mae_mean'])
        (best_channel_mae, best_dropout_mae, best_head_mae), best_stats_mae = best_param_avg_mae
        
        print("\n" + "="*80)
        print(f"é¢„æµ‹é•¿åº¦ {pred_len} - ğŸ† æœ€ä½³å‚æ•°ç»„åˆï¼ˆæŒ‰å¹³å‡ MAEï¼‰")
        print("="*80)
        print(f"Channel:     {best_channel_mae}")
        print(f"Dropout:     {best_dropout_mae}")
        print(f"Head:        {best_head_mae}")
        print(f"å¹³å‡ MSE:    {best_stats_mae['mse_mean']:.6f}")
        print(f"æœ€å° MSE:    {best_stats_mae['mse_min']:.6f}")
        print(f"æœ€å¤§ MSE:    {best_stats_mae['mse_max']:.6f}")
        print(f"å¹³å‡ MAE:    {best_stats_mae['mae_mean']:.6f}")
        print(f"æœ€å° MAE:    {best_stats_mae['mae_min']:.6f}")
        print(f"æœ€å¤§ MAE:    {best_stats_mae['mae_max']:.6f}")
        print(f"å®éªŒæ¬¡æ•°:    {best_stats_mae['count']}")

def print_summary_table(results_by_pred_len, pred_lens=[96, 192, 336, 720], data_path=None, 
                        model_id=None, model=None, model_id_prefix=None):
    """æ‰“å°æ‰€æœ‰é¢„æµ‹é•¿åº¦çš„æ±‡æ€»è¡¨æ ¼"""
    print("\n" + "="*80)
    print("ğŸ“Š æ‰€æœ‰é¢„æµ‹é•¿åº¦çš„æœ€ä½³ç»“æœæ±‡æ€»ï¼ˆè·¨æ‰€æœ‰ç§å­ï¼‰")
    if data_path:
        print(f"æ•°æ®é›†: {data_path}")
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    model_info = []
    if model_id:
        model_info.append(f"model_id: {model_id}")
    if model:
        model_info.append(f"model: {model}")
    if model_id_prefix:
        model_info.append(f"model_id_prefix: {model_id_prefix}")
    if model_info:
        print(f"æ¨¡å‹: {', '.join(model_info)}")
    
    print("="*80)
    
    # MSE æ±‡æ€»ï¼ˆæ·»åŠ ç»¼åˆå‡å€¼ï¼‰
    print("\nã€æœ€å° MSE æ±‡æ€»ã€‘")
    print(f"{'Pred_Len':<12} {'Seed':<8} {'Channel':<10} {'Dropout':<10} {'Head':<8} {'LR':<12} {'WD':<12} {'BS':<8} {'MSE':<15} {'MAE':<15}")
    print("-"*110)
    
    mse_values = []
    mae_values = []
    
    for pred_len in pred_lens:
        data = results_by_pred_len.get(pred_len, {})
        best_mse = data.get('best_mse')
        if best_mse:
            seed = best_mse.get('seed', 'N/A')
            mse_val = best_mse.get('test_mse')
            mae_val = best_mse.get('test_mae')
            
            if mse_val is not None:
                mse_values.append(mse_val)
            if mae_val is not None:
                mae_values.append(mae_val)
            
            print(f"{pred_len:<12} {seed:<8} {best_mse.get('channel', 'N/A'):<10} "
                  f"{best_mse.get('dropout_n', 'N/A'):<10.1f} {best_mse.get('head', 'N/A'):<8} "
                  f"{best_mse.get('learning_rate', 'N/A'):<12} {best_mse.get('weight_decay', 'N/A'):<12} "
                  f"{best_mse.get('batch_size', 'N/A'):<8} "
                  f"{mse_val:<15.6f} {mae_val:<15.6f}")
        else:
            print(f"{pred_len:<12} {'N/A':<8} {'N/A':<10} {'N/A':<10} {'N/A':<8} {'N/A':<12} {'N/A':<12} {'N/A':<8} {'N/A':<15} {'N/A':<15}")
    
    # æ˜¾ç¤ºç»¼åˆå‡å€¼
    if mse_values and mae_values:
        mse_avg = sum(mse_values) / len(mse_values)
        mae_avg = sum(mae_values) / len(mae_values)
        print("-"*110)
        print(f"{'ç»¼åˆå‡å€¼':<12} {'':<8} {'':<10} {'':<10} {'':<8} {'':<12} {'':<12} {'':<8} "
              f"{mse_avg:<15.6f} {mae_avg:<15.6f}")
    
    # MAE æ±‡æ€»ï¼ˆæ·»åŠ ç»¼åˆå‡å€¼ï¼‰
    print("\nã€æœ€å° MAE æ±‡æ€»ã€‘")
    print(f"{'Pred_Len':<12} {'Seed':<8} {'Channel':<10} {'Dropout':<10} {'Head':<8} {'LR':<12} {'WD':<12} {'BS':<8} {'MSE':<15} {'MAE':<15}")
    print("-"*110)
    
    mse_values_mae = []
    mae_values_mae = []
    
    for pred_len in pred_lens:
        data = results_by_pred_len.get(pred_len, {})
        best_mae = data.get('best_mae')
        if best_mae:
            seed = best_mae.get('seed', 'N/A')
            mse_val = best_mae.get('test_mse')
            mae_val = best_mae.get('test_mae')
            
            if mse_val is not None:
                mse_values_mae.append(mse_val)
            if mae_val is not None:
                mae_values_mae.append(mae_val)
            
            print(f"{pred_len:<12} {seed:<8} {best_mae.get('channel', 'N/A'):<10} "
                  f"{best_mae.get('dropout_n', 'N/A'):<10.1f} {best_mae.get('head', 'N/A'):<8} "
                  f"{best_mae.get('learning_rate', 'N/A'):<12} {best_mae.get('weight_decay', 'N/A'):<12} "
                  f"{best_mae.get('batch_size', 'N/A'):<8} "
                  f"{mse_val:<15.6f} {mae_val:<15.6f}")
        else:
            print(f"{pred_len:<12} {'N/A':<8} {'N/A':<10} {'N/A':<10} {'N/A':<8} {'N/A':<12} {'N/A':<12} {'N/A':<8} {'N/A':<15} {'N/A':<15}")
    
    # æ˜¾ç¤ºç»¼åˆå‡å€¼
    if mse_values_mae and mae_values_mae:
        mse_avg_mae = sum(mse_values_mae) / len(mse_values_mae)
        mae_avg_mae = sum(mae_values_mae) / len(mae_values_mae)
        print("-"*110)
        print(f"{'ç»¼åˆå‡å€¼':<12} {'':<8} {'':<10} {'':<10} {'':<8} {'':<12} {'':<12} {'':<8} "
              f"{mse_avg_mae:<15.6f} {mae_avg_mae:<15.6f}")

def export_best_configs_to_json(results_by_pred_len, pred_lens=[96, 192, 336, 720], data_path=None, output_file=None):
    """
    å¯¼å‡ºæœ€ä½³MSEå’Œæœ€ä½³MAEçš„é…ç½®åˆ°JSONæ–‡ä»¶
    
    Args:
        results_by_pred_len: æŒ‰é¢„æµ‹é•¿åº¦åˆ†ç»„çš„ç»“æœ
        pred_lens: é¢„æµ‹é•¿åº¦åˆ—è¡¨
        data_path: æ•°æ®é›†åç§°
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
    """
    if output_file is None:
        if data_path:
            output_file = f"best_configs_{data_path}.json"
        else:
            output_file = "best_configs.json"
    
    best_configs = {
        "dataset": data_path,
        "export_timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "best_mse_configs": [],
        "best_mae_configs": []
    }
    
    # æ”¶é›†æœ€ä½³MSEé…ç½®
    for pred_len in pred_lens:
        data = results_by_pred_len.get(pred_len, {})
        best_mse = data.get('best_mse')
        if best_mse:
            config = {
                "pred_len": pred_len,
                "seed": best_mse.get('seed'),
                "channel": best_mse.get('channel'),
                "dropout_n": best_mse.get('dropout_n'),
                "head": best_mse.get('head'),
                "e_layer": best_mse.get('e_layer'),
                "d_layer": best_mse.get('d_layer'),
                "learning_rate": best_mse.get('learning_rate'),
                "weight_decay": best_mse.get('weight_decay'),
                "batch_size": best_mse.get('batch_size'),
                "seq_len": best_mse.get('seq_len'),
                "loss_fn": best_mse.get('loss_fn'),
                "lradj": best_mse.get('lradj'),
                "embed_version": best_mse.get('embed_version'),
                "epochs": best_mse.get('epochs'),
                "patience": best_mse.get('patience'),
                "test_mse": best_mse.get('test_mse'),
                "test_mae": best_mse.get('test_mae'),
                "timestamp": best_mse.get('timestamp'),
                "model_id": best_mse.get('model_id')
            }
            best_configs["best_mse_configs"].append(config)
    
    # æ”¶é›†æœ€ä½³MAEé…ç½®
    for pred_len in pred_lens:
        data = results_by_pred_len.get(pred_len, {})
        best_mae = data.get('best_mae')
        if best_mae:
            config = {
                "pred_len": pred_len,
                "seed": best_mae.get('seed'),
                "channel": best_mae.get('channel'),
                "dropout_n": best_mae.get('dropout_n'),
                "head": best_mae.get('head'),
                "e_layer": best_mae.get('e_layer'),
                "d_layer": best_mae.get('d_layer'),
                "learning_rate": best_mae.get('learning_rate'),
                "weight_decay": best_mae.get('weight_decay'),
                "batch_size": best_mae.get('batch_size'),
                "seq_len": best_mae.get('seq_len'),
                "loss_fn": best_mae.get('loss_fn'),
                "lradj": best_mae.get('lradj'),
                "embed_version": best_mae.get('embed_version'),
                "epochs": best_mae.get('epochs'),
                "patience": best_mae.get('patience'),
                "test_mse": best_mae.get('test_mse'),
                "test_mae": best_mae.get('test_mae'),
                "timestamp": best_mae.get('timestamp'),
                "model_id": best_mae.get('model_id')
            }
            best_configs["best_mae_configs"].append(config)
    
    # ä¿å­˜åˆ°JSONæ–‡ä»¶
    output_path = os.path.join(project_root, output_file)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(best_configs, f, ensure_ascii=False, indent=2)
    
    print("\n" + "="*80)
    print(f"âœ… æœ€ä½³é…ç½®å·²å¯¼å‡ºåˆ°: {output_path}")
    print(f"   - æœ€ä½³MSEé…ç½®æ•°é‡: {len(best_configs['best_mse_configs'])}")
    print(f"   - æœ€ä½³MAEé…ç½®æ•°é‡: {len(best_configs['best_mae_configs'])}")
    print("="*80)
    
    return output_path

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='æ£€ç´¢ T3Time_FreTS_FusionExp æ¨¡å‹çš„æ‰€æœ‰ç§å­çš„å‚æ•°å¯»ä¼˜å®éªŒç»“æœï¼ˆæŒ‰é¢„æµ‹é•¿åº¦åˆ†åˆ«åˆ†æï¼‰'
    )
    parser.add_argument('--result_file', type=str, default=None,
                        help='ç»“æœæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: experiment_results.logï¼‰')
    parser.add_argument('--seed', type=int, default=None,
                        help='éšæœºç§å­ï¼ˆé»˜è®¤: Noneï¼Œåˆ†ææ‰€æœ‰ç§å­ï¼‰')
    parser.add_argument('--model_id', type=str, default=None,
                        help='ç²¾ç¡®åŒ¹é…çš„model_id')
    parser.add_argument('--model', type=str, default=None,
                        help='ç²¾ç¡®åŒ¹é…çš„modelåç§°')
    parser.add_argument('--model_id_prefix', type=str, default=None,
                        help='æ¨¡å‹IDå‰ç¼€ï¼ˆå¦‚æœæœªæŒ‡å®šmodel_idå’Œmodelï¼Œä¸”æœªäº¤äº’é€‰æ‹©ï¼Œåˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼‰')
    parser.add_argument('--pred_lens', type=int, nargs='+',
                        default=[96, 192, 336, 720],
                        help='è¦åˆ†æçš„é¢„æµ‹é•¿åº¦åˆ—è¡¨ï¼ˆé»˜è®¤: 96 192 336 720ï¼‰')
    parser.add_argument('--data_path', type=str, default=None,
                        help='æ•°æ®é›†åç§°ï¼ˆé»˜è®¤: Noneï¼Œå°†æ˜¾ç¤ºäº¤äº’å¼èœå•é€‰æ‹©ï¼›ä¾‹å¦‚: ETTh1, ETTh2, ETTm1, ETTm2ï¼‰')
    
    args = parser.parse_args()
    
    # å¦‚æœæœªæŒ‡å®šæ¨¡å‹ï¼Œåˆ™æ˜¾ç¤ºäº¤äº’å¼èœå•
    model_id = args.model_id
    model = args.model
    model_id_prefix = args.model_id_prefix
    
    if model_id is None and model is None and model_id_prefix is None:
        model_id, model, model_id_prefix = interactive_select_model(result_file=args.result_file)
        if model_id is None and model is None and model_id_prefix is None:
            print("\nç¨‹åºå·²é€€å‡º")
            return
    
    # å¦‚æœä»æœªæŒ‡å®šï¼Œä½¿ç”¨é»˜è®¤å‰ç¼€
    if model_id is None and model is None and model_id_prefix is None:
        model_id_prefix = 'T3Time_FreTS_Gated_Qwen_Hyperopt'
        print(f"\nä½¿ç”¨é»˜è®¤ model_id å‰ç¼€: {model_id_prefix}")
    
    # å¦‚æœæœªæŒ‡å®šæ•°æ®é›†ï¼Œåˆ™æ˜¾ç¤ºäº¤äº’å¼èœå•
    data_path = args.data_path
    if data_path is None:
        data_path = interactive_select_dataset(
            result_file=args.result_file,
            model_id=model_id,
            model=model,
            model_id_prefix=model_id_prefix
        )
        if data_path is None:
            print("\nç¨‹åºå·²é€€å‡º")
            return
    
    results = load_hyperopt_results(
        result_file=args.result_file,
        seed=args.seed,
        model_id=model_id,
        model=model,
        model_id_prefix=model_id_prefix,
        data_path=data_path,
    )
    
    if not results:
        model_desc = ""
        if model_id:
            model_desc = f"model_id={model_id}"
        elif model:
            model_desc = f"model={model}"
        elif model_id_prefix:
            model_desc = f"model_id_prefix={model_id_prefix}"
        else:
            model_desc = "æ‰€æœ‰æ¨¡å‹"
        
        if args.seed is None:
            print(f"\nâŒ æœªæ‰¾åˆ° {model_desc} çš„ä»»ä½•å®éªŒç»“æœ")
        else:
            print(f"\nâŒ æœªæ‰¾åˆ° {model_desc}, seed={args.seed} çš„å®éªŒç»“æœ")
        print("è¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æˆ–è¿è¡Œç›¸åº”çš„å®éªŒè„šæœ¬")
        return
    
    # æŒ‰é¢„æµ‹é•¿åº¦åˆ†ç»„åˆ†æ
    results_by_pred_len = find_best_params_by_pred_len(results, args.pred_lens)
    
    # æ‰“å°æ±‡æ€»è¡¨æ ¼
    print_summary_table(results_by_pred_len, args.pred_lens, data_path=data_path,
                       model_id=model_id, model=model, model_id_prefix=model_id_prefix)
    
    # å¯¼å‡ºæœ€ä½³é…ç½®åˆ°JSONæ–‡ä»¶
    export_best_configs_to_json(results_by_pred_len, args.pred_lens, data_path=data_path)
    
    # æ‰“å°æ¯ä¸ªé¢„æµ‹é•¿åº¦çš„è¯¦ç»†ç»“æœï¼ˆä¼ å…¥æ‰€æœ‰ç»“æœç”¨äºç§å­ç»Ÿè®¡ï¼‰
    # print_results_by_pred_len(results_by_pred_len, args.pred_lens, all_results=results, data_path=data_path)
    
    # print("\n" + "="*80)
    # print("åˆ†æå®Œæˆï¼")
    # print("="*80)

if __name__ == "__main__":
    main()
